{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baac647e-bac3-4cb4-b9e2-03ce9ee79c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n",
      "GPU Name: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spectral\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "from HSI_class import HSI\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "\n",
    "# If available, print the GPU name\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96a6d3fd-1134-48ce-beeb-575479dc41b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Hyperspectral oil spill detection datasets\\GM01.mat\n",
      "Processing file: Hyperspectral oil spill detection datasets\\GM02.mat\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"Hyperspectral oil spill detection datasets\"\n",
    "\n",
    "dataset = []\n",
    "\n",
    "i = 0\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if i > 1:\n",
    "        break\n",
    "    file_path = os.path.join(dataset_path, filename)\n",
    "    if os.path.isfile(file_path):  # Check if it's a file\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        hsi = HSI(file_path)\n",
    "        dataset.append(hsi)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f7975a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GM01: (1243, 684, 224)\n",
      "GM02: (1786, 699, 224)\n"
     ]
    }
   ],
   "source": [
    "for hsi in dataset:\n",
    "    print(f'{hsi.name}: {hsi.img.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cb884a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1786, 699, 224)\n",
      "(1786, 699)\n",
      "(1786, 699)\n",
      "1236269\n",
      "12145\n"
     ]
    }
   ],
   "source": [
    "data = dataset[1]\n",
    "print(data.img.shape)\n",
    "print(data.gt.shape)\n",
    "\n",
    "arr = data.gt\n",
    "\n",
    "print(arr.shape)\n",
    "\n",
    "count = np.count_nonzero(arr == 0)  # Count elements equal to 0\n",
    "print(count)\n",
    "\n",
    "count = np.count_nonzero(arr == 1)  # Count elements equal to 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a70b100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hsi shape\n",
      "(1243, 684, 224)\n",
      "5 Randomly chosen 0 indices: [(np.int64(386), np.int64(623)), (np.int64(332), np.int64(168)), (np.int64(1184), np.int64(200)), (np.int64(922), np.int64(172)), (np.int64(572), np.int64(621)), (np.int64(539), np.int64(153)), (np.int64(1), np.int64(105)), (np.int64(1040), np.int64(345)), (np.int64(197), np.int64(412)), (np.int64(798), np.int64(251)), (np.int64(1135), np.int64(199)), (np.int64(756), np.int64(236)), (np.int64(1147), np.int64(138)), (np.int64(243), np.int64(258)), (np.int64(856), np.int64(579)), (np.int64(741), np.int64(153)), (np.int64(520), np.int64(616)), (np.int64(793), np.int64(191)), (np.int64(1101), np.int64(209)), (np.int64(1137), np.int64(574))]\n",
      "5 Randomly chosen 1 indices: [(np.int64(152), np.int64(101)), (np.int64(266), np.int64(161)), (np.int64(454), np.int64(530)), (np.int64(1016), np.int64(102)), (np.int64(1038), np.int64(113)), (np.int64(520), np.int64(296)), (np.int64(662), np.int64(70)), (np.int64(981), np.int64(68)), (np.int64(127), np.int64(139)), (np.int64(1083), np.int64(134)), (np.int64(98), np.int64(64)), (np.int64(663), np.int64(67)), (np.int64(270), np.int64(278)), (np.int64(601), np.int64(442)), (np.int64(379), np.int64(584)), (np.int64(377), np.int64(242)), (np.int64(933), np.int64(568)), (np.int64(398), np.int64(256)), (np.int64(271), np.int64(220)), (np.int64(940), np.int64(590))]\n",
      "(1243, 684, 224)\n",
      "(1251, 692, 224)\n",
      "seed pixel in data class 0\n",
      "[-234 -222  425  441  464  599  676  672  660  626  587  545  498  456\n",
      "  435  403  385  358  332  303  279  259  233  217  191  174  162  153\n",
      "  143  138  133  126  123  119  102   93   80   70   62   29   48   61\n",
      "   66   31   47   56   51   44   43   18   28   33   47   42   45   39\n",
      "   39   16    4   -5    0  -55 -179  -71    6   12   27   35   37   40\n",
      "   41   37   35   33   36   27   22   17    3  -23 -236 -249 -130 -126\n",
      "  -38   -3    2    2   14    6   20   19   23   22   28   25   26   29\n",
      "   29   30   27   24   13   94  -18  -74    0    0    0    0    0    0\n",
      "    0    0 -170 -304  -72  -62  -72  -58   -3   12   22   22   29   28\n",
      "   41   30   36   36   37   37   38   37   33   37   34   32   31   37\n",
      "   36   39   40   45   30   13   25   13    6   -9  -21 -132    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  -60  -91  -11   -4    5    6  -22   11   13   23   26   24   15   24\n",
      "   29   24   30   29   31   27   35   32   31   27   29   30   24   31\n",
      "   31   28   27   37   40   31   27   39   36   21   26   25   30   19\n",
      "    8    4    6   24   27  -24   13   -4   10  -12  -30   45  -18  -21]\n",
      "seed pixel in selected patch class 0\n",
      "[-234. -222.  425.  441.  464.  599.  676.  672.  660.  626.  587.  545.\n",
      "  498.  456.  435.  403.  385.  358.  332.  303.  279.  259.  233.  217.\n",
      "  191.  174.  162.  153.  143.  138.  133.  126.  123.  119.  102.   93.\n",
      "   80.   70.   62.   29.   48.   61.   66.   31.   47.   56.   51.   44.\n",
      "   43.   18.   28.   33.   47.   42.   45.   39.   39.   16.    4.   -5.\n",
      "    0.  -55. -179.  -71.    6.   12.   27.   35.   37.   40.   41.   37.\n",
      "   35.   33.   36.   27.   22.   17.    3.  -23. -236. -249. -130. -126.\n",
      "  -38.   -3.    2.    2.   14.    6.   20.   19.   23.   22.   28.   25.\n",
      "   26.   29.   29.   30.   27.   24.   13.   94.  -18.  -74.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0. -170. -304.  -72.  -62.  -72.  -58.\n",
      "   -3.   12.   22.   22.   29.   28.   41.   30.   36.   36.   37.   37.\n",
      "   38.   37.   33.   37.   34.   32.   31.   37.   36.   39.   40.   45.\n",
      "   30.   13.   25.   13.    6.   -9.  -21. -132.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  -60.  -91.  -11.   -4.    5.    6.  -22.   11.   13.   23.   26.   24.\n",
      "   15.   24.   29.   24.   30.   29.   31.   27.   35.   32.   31.   27.\n",
      "   29.   30.   24.   31.   31.   28.   27.   37.   40.   31.   27.   39.\n",
      "   36.   21.   26.   25.   30.   19.    8.    4.    6.   24.   27.  -24.\n",
      "   13.   -4.   10.  -12.  -30.   45.  -18.  -21.]\n",
      "seed pixel in data class 1\n",
      "[-270 -580  249  382  416  563  634  650  616  595  562  511  485  452\n",
      "  431  412  401  384  370  345  332  320  318  300  291  280  269  273\n",
      "  277  270  270  272  279  263  263  252  237  226  221  190  188  181\n",
      "  189  167  184  185  180  180  179  163  160  155  167  159  154  142\n",
      "  141  113   92   74   78   45  -89   -3   66   77   88  100  111  114\n",
      "  125  121  128  126  128  114  101   88   66   29 -153 -196  -89  -81\n",
      "  -10   28   44   43   56   54   72   69   77   76   76   83   81   77\n",
      "   71   81   61   53   41  -22  -17  -31    0    0    0    0    0    0\n",
      "    0    0 -207 -185  -85  -47  -86  -44   11   19   33   43   40   47\n",
      "   48   52   53   55   56   57   55   59   55   58   58   58   52   52\n",
      "   52   69   61   54   54   36   33   25   23    6   20  -70    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  -40  -28   16    6    1   -9    2   -1   25   23   30   31   32   36\n",
      "   36   42   34   36   39   38   35   44   35   35   38   40   41   47\n",
      "   40   41   41   45   48   50   42   36   50   33   38   26   15   32\n",
      "   15   22    7    4   -1   -9    0  -20  -17  -28   -1  -54  -20  -23]\n",
      "seed pixel in selected patch class 1\n",
      "[-270. -580.  249.  382.  416.  563.  634.  650.  616.  595.  562.  511.\n",
      "  485.  452.  431.  412.  401.  384.  370.  345.  332.  320.  318.  300.\n",
      "  291.  280.  269.  273.  277.  270.  270.  272.  279.  263.  263.  252.\n",
      "  237.  226.  221.  190.  188.  181.  189.  167.  184.  185.  180.  180.\n",
      "  179.  163.  160.  155.  167.  159.  154.  142.  141.  113.   92.   74.\n",
      "   78.   45.  -89.   -3.   66.   77.   88.  100.  111.  114.  125.  121.\n",
      "  128.  126.  128.  114.  101.   88.   66.   29. -153. -196.  -89.  -81.\n",
      "  -10.   28.   44.   43.   56.   54.   72.   69.   77.   76.   76.   83.\n",
      "   81.   77.   71.   81.   61.   53.   41.  -22.  -17.  -31.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0. -207. -185.  -85.  -47.  -86.  -44.\n",
      "   11.   19.   33.   43.   40.   47.   48.   52.   53.   55.   56.   57.\n",
      "   55.   59.   55.   58.   58.   58.   52.   52.   52.   69.   61.   54.\n",
      "   54.   36.   33.   25.   23.    6.   20.  -70.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  -40.  -28.   16.    6.    1.   -9.    2.   -1.   25.   23.   30.   31.\n",
      "   32.   36.   36.   42.   34.   36.   39.   38.   35.   44.   35.   35.\n",
      "   38.   40.   41.   47.   40.   41.   41.   45.   48.   50.   42.   36.\n",
      "   50.   33.   38.   26.   15.   32.   15.   22.    7.    4.   -1.   -9.\n",
      "    0.  -20.  -17.  -28.   -1.  -54.  -20.  -23.]\n"
     ]
    }
   ],
   "source": [
    "import createSample as CS\n",
    "hsi_ = dataset[0]\n",
    "patch_size = 9\n",
    "sample_per_class = 20\n",
    "selected_patch_0, selected_patch_1, random_indices_0, random_indices_1 = CS.createSample(hsi_, patch_size, sample_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed277ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "gt = hsi_.gt\n",
    "\n",
    "for indice in random_indices_1:\n",
    "    print(gt[indice[0]][indice[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b41b171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-198 -433  313  371  423  571  645  661  652  617  591  540  502  470\n",
      "  448  422  400  372  346  317  291  271  256  226  212  199  184  176\n",
      "  175  165  163  154  149  142  128  121  107  100   88   72   82   83\n",
      "   88   72   83   82   79   75   75   67   64   73   82   74   79   72\n",
      "   69   53   35   27   18  -30  -75  -30   42   51   62   80   88   92\n",
      "   94   92   96   86   87   77   63   51   36    9  -82 -107  -86  -86\n",
      "   -9   24   37   43   60   61   73   71   82   80   86   91   91   93\n",
      "  102   87   79   67   53   28    9   -2  -45    0    0    0    0    0\n",
      "    0  -72  -37  -48  -64  -36  -37  -31   23   35   51   64   72   69\n",
      "   81   86   84   88   91   91   90   88   86   91   89   86   82   86\n",
      "   85   83   80   77   69   61   56   37   27   22    4   -1  -32    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "   -5  -15    6    6    7   10    0   46   34   43   47   52   53   62\n",
      "   60   62   62   61   69   64   70   65   71   67   72   74   73   67\n",
      "   72   68   68   68   75   61   66   68   60   60   42   41   34   47\n",
      "   26   18   13   13   -3    0    7    0  -18   -3   -9  -12    0  -50]\n",
      "[-198. -433.  313.  371.  423.  571.  645.  661.  652.  617.  591.  540.\n",
      "  502.  470.  448.  422.  400.  372.  346.  317.  291.  271.  256.  226.\n",
      "  212.  199.  184.  176.  175.  165.  163.  154.  149.  142.  128.  121.\n",
      "  107.  100.   88.   72.   82.   83.   88.   72.   83.   82.   79.   75.\n",
      "   75.   67.   64.   73.   82.   74.   79.   72.   69.   53.   35.   27.\n",
      "   18.  -30.  -75.  -30.   42.   51.   62.   80.   88.   92.   94.   92.\n",
      "   96.   86.   87.   77.   63.   51.   36.    9.  -82. -107.  -86.  -86.\n",
      "   -9.   24.   37.   43.   60.   61.   73.   71.   82.   80.   86.   91.\n",
      "   91.   93.  102.   87.   79.   67.   53.   28.    9.   -2.  -45.    0.\n",
      "    0.    0.    0.    0.    0.  -72.  -37.  -48.  -64.  -36.  -37.  -31.\n",
      "   23.   35.   51.   64.   72.   69.   81.   86.   84.   88.   91.   91.\n",
      "   90.   88.   86.   91.   89.   86.   82.   86.   85.   83.   80.   77.\n",
      "   69.   61.   56.   37.   27.   22.    4.   -1.  -32.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   -5.  -15.    6.    6.    7.   10.    0.   46.   34.   43.   47.   52.\n",
      "   53.   62.   60.   62.   62.   61.   69.   64.   70.   65.   71.   67.\n",
      "   72.   74.   73.   67.   72.   68.   68.   68.   75.   61.   66.   68.\n",
      "   60.   60.   42.   41.   34.   47.   26.   18.   13.   13.   -3.    0.\n",
      "    7.    0.  -18.   -3.   -9.  -12.    0.  -50.]\n",
      "[-262 -643  257  333  380  509  596  597  560  529  491  447  416  387\n",
      "  369  345  336  322  313  304  289  286  272  280  280  282  276  285\n",
      "  294  302  313  316  309  306  310  307  301  315  319  332  326  334\n",
      "  343  367  375  384  385  395  410  428  435  443  455  463  466  464\n",
      "  469  443  400  377  370  425  455  473  477  491  517  568  620  643\n",
      "  665  673  674  667  658  631  566  496  445  393  315  221  367  359\n",
      "  331  365  421  462  521  566  600  617  634  655  683  719  723  702\n",
      "  654  624  557  519  551  323  562  498    0    0    0    0    0    0\n",
      "    0    0 -207  -26   31   92  100  196  252  264  296  326  364  366\n",
      "  422  435  453  467  480  479  485  495  479  477  467  450  435  437\n",
      "  408  399  381  338  320  282  280  248  247  247  259  183    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  -14  -28   58   57   76  112  155  176  184  196  225  254  282  286\n",
      "  303  320  320  334  344  341  352  358  361  364  364  363  366  356\n",
      "  344  328  301  278  251  211  188  176  134  132  140  119  136  112\n",
      "  100  100   79   84   79   41   51   43   41   22   -1   31   59   33]\n",
      "[-262. -643.  257.  333.  380.  509.  596.  597.  560.  529.  491.  447.\n",
      "  416.  387.  369.  345.  336.  322.  313.  304.  289.  286.  272.  280.\n",
      "  280.  282.  276.  285.  294.  302.  313.  316.  309.  306.  310.  307.\n",
      "  301.  315.  319.  332.  326.  334.  343.  367.  375.  384.  385.  395.\n",
      "  410.  428.  435.  443.  455.  463.  466.  464.  469.  443.  400.  377.\n",
      "  370.  425.  455.  473.  477.  491.  517.  568.  620.  643.  665.  673.\n",
      "  674.  667.  658.  631.  566.  496.  445.  393.  315.  221.  367.  359.\n",
      "  331.  365.  421.  462.  521.  566.  600.  617.  634.  655.  683.  719.\n",
      "  723.  702.  654.  624.  557.  519.  551.  323.  562.  498.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0. -207.  -26.   31.   92.  100.  196.\n",
      "  252.  264.  296.  326.  364.  366.  422.  435.  453.  467.  480.  479.\n",
      "  485.  495.  479.  477.  467.  450.  435.  437.  408.  399.  381.  338.\n",
      "  320.  282.  280.  248.  247.  247.  259.  183.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  -14.  -28.   58.   57.   76.  112.  155.  176.  184.  196.  225.  254.\n",
      "  282.  286.  303.  320.  320.  334.  344.  341.  352.  358.  361.  364.\n",
      "  364.  363.  366.  356.  344.  328.  301.  278.  251.  211.  188.  176.\n",
      "  134.  132.  140.  119.  136.  112.  100.  100.   79.   84.   79.   41.\n",
      "   51.   43.   41.   22.   -1.   31.   59.   33.]\n"
     ]
    }
   ],
   "source": [
    "i =0\n",
    "half_patch = patch_size // 2\n",
    "print(hsi_.img[random_indices_0[i][0]][random_indices_0[i][1]])\n",
    "print(selected_patch_0[i][half_patch][half_patch])\n",
    "\n",
    "print(hsi_.img[random_indices_1[i][0]][random_indices_1[i][1]])\n",
    "print(selected_patch_1[i][half_patch][half_patch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51a50f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected patch 0: (20, 9, 9, 224)\n",
      "selected patch 1: (20, 9, 9, 224)\n",
      "[(np.int64(522), np.int64(139)), (np.int64(714), np.int64(298)), (np.int64(298), np.int64(453)), (np.int64(262), np.int64(563)), (np.int64(744), np.int64(384)), (np.int64(145), np.int64(295)), (np.int64(970), np.int64(151)), (np.int64(683), np.int64(74)), (np.int64(534), np.int64(568)), (np.int64(366), np.int64(62)), (np.int64(1190), np.int64(4)), (np.int64(249), np.int64(134)), (np.int64(317), np.int64(362)), (np.int64(227), np.int64(478)), (np.int64(929), np.int64(236)), (np.int64(72), np.int64(4)), (np.int64(1228), np.int64(55)), (np.int64(750), np.int64(585)), (np.int64(265), np.int64(95)), (np.int64(959), np.int64(124))]\n",
      "[(np.int64(86), np.int64(113)), (np.int64(163), np.int64(124)), (np.int64(319), np.int64(280)), (np.int64(480), np.int64(481)), (np.int64(573), np.int64(632)), (np.int64(219), np.int64(496)), (np.int64(332), np.int64(224)), (np.int64(1206), np.int64(161)), (np.int64(704), np.int64(638)), (np.int64(1071), np.int64(107)), (np.int64(956), np.int64(621)), (np.int64(771), np.int64(450)), (np.int64(422), np.int64(258)), (np.int64(1171), np.int64(150)), (np.int64(174), np.int64(66)), (np.int64(682), np.int64(63)), (np.int64(271), np.int64(223)), (np.int64(579), np.int64(618)), (np.int64(336), np.int64(526)), (np.int64(185), np.int64(157))]\n"
     ]
    }
   ],
   "source": [
    "print(f\"selected patch 0: {selected_patch_0.shape}\")\n",
    "print(f\"selected patch 1: {selected_patch_1.shape}\")\n",
    "\n",
    "print(random_indices_0)\n",
    "print(random_indices_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b00873c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 9, 9, 224)\n",
      "(40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "indices = random_indices_0 +  random_indices_1\n",
    "\n",
    "# Concatenating along axis 0\n",
    "x_train = np.concatenate((selected_patch_0, selected_patch_1), )\n",
    "zero = np.zeros(20)\n",
    "one = np.ones(20)\n",
    "y_train = np.concatenate((zero, one))\n",
    "# Print shape to verify\n",
    "print(x_train.shape)  # Expected output: (10, 9, 9, 224)\n",
    "print(y_train.shape) \n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89d95d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j:  400\n"
     ]
    }
   ],
   "source": [
    "# Augmentation\n",
    "import augmentation as aug\n",
    "\n",
    "n_category = 2\n",
    "band_size = 224\n",
    "num_per_category = 200\n",
    "\n",
    "data_augment1, label_augment1 = aug.Augment_data(x_train, y_train, n_category, patch_size, band_size, num_per_category)\n",
    "\n",
    "data_augment2, label_augment2 = aug.Augment_data2(x_train, y_train, n_category, patch_size, band_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f671360d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 9, 9, 224)\n",
      "(400,)\n",
      "(400, 9, 9, 224)\n",
      "(400,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Element 0 occurs 200 times.\n",
      "Element 1 occurs 200 times.\n",
      "Element 0 occurs 200 times.\n",
      "Element 1 occurs 200 times.\n"
     ]
    }
   ],
   "source": [
    "print(data_augment1.shape)\n",
    "print(label_augment1.shape)\n",
    "\n",
    "print(data_augment2.shape)\n",
    "print(label_augment2.shape)\n",
    "\n",
    "print(label_augment1)\n",
    "print(label_augment2)\n",
    "\n",
    "# Count occurrences of each unique element\n",
    "counts1 = np.bincount(label_augment1)\n",
    "\n",
    "# Print results\n",
    "for i, count in enumerate(counts1):\n",
    "    print(f\"Element {i} occurs {count} times.\")\n",
    "\n",
    "counts2 = np.bincount(label_augment2)\n",
    "\n",
    "# Print results\n",
    "for i, count in enumerate(counts2):\n",
    "    print(f\"Element {i} occurs {count} times.\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fda18623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 9, 9, 224)\n",
      "(800,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Element 0 occurs 400 times.\n",
      "Element 1 occurs 400 times.\n"
     ]
    }
   ],
   "source": [
    "data_augment = np.concatenate((data_augment1, data_augment2))\n",
    "label_augment = np.concatenate((label_augment1, label_augment2))\n",
    "\n",
    "print(data_augment.shape)\n",
    "print(label_augment.shape)\n",
    "\n",
    "print(label_augment)\n",
    "\n",
    "# Count occurrences of each unique element\n",
    "counts = np.bincount(label_augment)\n",
    "\n",
    "# Print results\n",
    "for i, count in enumerate(counts):\n",
    "    print(f\"Element {i} occurs {count} times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b892dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.models import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96286986",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16_HSI(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(VGG16_HSI, self).__init__()\n",
    "\n",
    "         # Custom Convolutional Layer: Process 9x9x224 input\n",
    "        self.pre_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=224, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))  # Reduce to (256, 1, 1)\n",
    "        )\n",
    "\n",
    "        # Fully Connected Layer to reshape to (64, 56, 56)\n",
    "        self.fc = nn.Linear(256 * 1 * 1, 64 * 56 * 56)\n",
    "\n",
    "        # Load VGG-16 Model\n",
    "        self.vgg = vgg16(pretrained=True)\n",
    "\n",
    "        # Remove first VGG-16 conv layer\n",
    "        self.vgg.features = nn.Sequential(*list(self.vgg.features.children())[1:])\n",
    "\n",
    "        # Modify classifier to output 2 classes\n",
    "        self.vgg.classifier[6] = nn.Linear(4096, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(f'before {x.shape}')\n",
    "        x = self.pre_conv(x)  # Process hyperspectral input\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "\n",
    "        # print(f'after preconv {x.shape}')\n",
    "        x = self.fc(x)  # Fully connected layer\n",
    "        # print(f'after fc {x.shape}')\n",
    "        # Reshape to (batch_size, 64, 56, 56) before passing to VGG\n",
    "        x = x.view(x.size(0), 64, 56, 56)\n",
    "        # print(f'after reshape, before vgg second layer {x.shape}')\n",
    "\n",
    "        x = self.vgg.features(x)  # Pass to VGG-16\n",
    "        x = self.vgg.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.vgg.classifier(x)  # Final classification layer\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a18f32a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 9, 224])\n"
     ]
    }
   ],
   "source": [
    "test = data_augment[0]\n",
    "test = torch.tensor(test)\n",
    "test = test.to(torch.float32)\n",
    "test = test.unsqueeze(0)\n",
    "\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99554f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus TUF\\Documents\\code\\TA\\myenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus TUF\\Documents\\code\\TA\\myenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model created\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "print(\"creating model...\")\n",
    "model = VGG16_HSI()\n",
    "print(\"model created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f64303c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16_HSI(\n",
      "  (pre_conv): Sequential(\n",
      "    (0): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=200704, bias=True)\n",
      "  (vgg): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): ReLU(inplace=True)\n",
      "      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU(inplace=True)\n",
      "      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (10): ReLU(inplace=True)\n",
      "      (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (12): ReLU(inplace=True)\n",
      "      (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (14): ReLU(inplace=True)\n",
      "      (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (16): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (17): ReLU(inplace=True)\n",
      "      (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (19): ReLU(inplace=True)\n",
      "      (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (21): ReLU(inplace=True)\n",
      "      (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (24): ReLU(inplace=True)\n",
      "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (26): ReLU(inplace=True)\n",
      "      (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (28): ReLU(inplace=True)\n",
      "      (29): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35acd309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape: torch.Size([1, 2])\n",
      "[[ 0.7149431 -0.7814042]]\n"
     ]
    }
   ],
   "source": [
    "input = test\n",
    "input = input.permute(0, 3, 1, 2)\n",
    "\n",
    "\n",
    "# Pass the input through the model\n",
    "output = model(input)\n",
    "\n",
    "# Print the output shape\n",
    "print(\"Output Shape:\", output.shape)\n",
    "\n",
    "output_value = output.detach().numpy() \n",
    "print(output_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f570c32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 224, 9, 9])\n",
      "torch.Size([800])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "num_train_samples = 800\n",
    "num_val_samples = 1000\n",
    "num_channels = 224  # Hyperspectral bands\n",
    "height, width = 9, 9\n",
    "\n",
    "X_train = data_augment\n",
    "X_train = torch.tensor(X_train)\n",
    "X_train = X_train.to(torch.float32)\n",
    "X_train = X_train.permute(0, 3, 1, 2)\n",
    "print(X_train.shape)\n",
    "\n",
    "y_train = torch.tensor(label_augment)\n",
    "\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b2951c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hsi shape\n",
      "(1243, 684, 224)\n",
      "5 Randomly chosen 0 indices: [(np.int64(937), np.int64(20)), (np.int64(96), np.int64(97)), (np.int64(539), np.int64(387)), (np.int64(272), np.int64(36)), (np.int64(262), np.int64(524)), (np.int64(615), np.int64(657)), (np.int64(104), np.int64(362)), (np.int64(346), np.int64(621)), (np.int64(1235), np.int64(84)), (np.int64(695), np.int64(607)), (np.int64(315), np.int64(294)), (np.int64(159), np.int64(350)), (np.int64(9), np.int64(443)), (np.int64(96), np.int64(371)), (np.int64(249), np.int64(531)), (np.int64(835), np.int64(233)), (np.int64(389), np.int64(218)), (np.int64(1133), np.int64(471)), (np.int64(520), np.int64(413)), (np.int64(791), np.int64(126))]\n",
      "5 Randomly chosen 1 indices: [(np.int64(59), np.int64(367)), (np.int64(623), np.int64(522)), (np.int64(308), np.int64(153)), (np.int64(1027), np.int64(73)), (np.int64(612), np.int64(414)), (np.int64(292), np.int64(639)), (np.int64(566), np.int64(254)), (np.int64(325), np.int64(176)), (np.int64(1172), np.int64(130)), (np.int64(927), np.int64(473)), (np.int64(261), np.int64(468)), (np.int64(210), np.int64(96)), (np.int64(869), np.int64(27)), (np.int64(101), np.int64(73)), (np.int64(263), np.int64(216)), (np.int64(258), np.int64(237)), (np.int64(82), np.int64(111)), (np.int64(548), np.int64(322)), (np.int64(224), np.int64(504)), (np.int64(529), np.int64(189))]\n",
      "(1243, 684, 224)\n",
      "(1251, 692, 224)\n",
      "937 20 937 20\n",
      "96 97 96 97\n",
      "539 387 539 387\n",
      "272 36 272 36\n",
      "262 524 262 524\n",
      "615 657 615 657\n",
      "104 362 104 362\n",
      "346 621 346 621\n",
      "1235 84 1235 84\n",
      "695 607 695 607\n",
      "315 294 315 294\n",
      "159 350 159 350\n",
      "9 443 9 443\n",
      "96 371 96 371\n",
      "249 531 249 531\n",
      "835 233 835 233\n",
      "389 218 389 218\n",
      "1133 471 1133 471\n",
      "520 413 520 413\n",
      "791 126 791 126\n",
      "59 367 59 367\n",
      "623 522 623 522\n",
      "308 153 308 153\n",
      "1027 73 1027 73\n",
      "612 414 612 414\n",
      "292 639 292 639\n",
      "566 254 566 254\n",
      "325 176 325 176\n",
      "1172 130 1172 130\n",
      "927 473 927 473\n",
      "261 468 261 468\n",
      "210 96 210 96\n",
      "869 27 869 27\n",
      "101 73 101 73\n",
      "263 216 263 216\n",
      "258 237 258 237\n",
      "82 111 82 111\n",
      "548 322 548 322\n",
      "224 504 224 504\n",
      "529 189 529 189\n",
      "seed pixel in data class 0\n",
      "[-155 -299  345  346  390  527  611  627  620  601  568  516  479  429\n",
      "  402  371  351  327  306  286  263  246  231  210  188  180  169  154\n",
      "  152  139  139  134  137  126  120  105   86   78   66   31   38   50\n",
      "   55   23   41   48   43   41   37   18   19   20   33   28   27   23\n",
      "   17   -1  -15  -17  -19  -86  -92 -113  -30  -19   -7   -3   -3   -1\n",
      "    0   -2    3    2    5    0   -3   -3  -17  -45  -56  -51  -68  -67\n",
      "  -56  -16  -16  -21  -20  -34  -24  -18  -15  -10   -8  -14   -8    0\n",
      "    7    4   -3   -7  -11  -44  -43  -51  -36    0    0    0    0    0\n",
      "    0    0    0    0    0    0  -17  -36  -23   -7   -2   -7   -6    1\n",
      "    1   -1    3    3    0    3   -1    5    9   -2    4   -1    3    0\n",
      "    0   -2    2    0    0   -2   -5  -13  -13  -17  -43  -10  -33    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  -14  -10  -10   -9   -6  -31  -31  -15   -7   -4  -14   -6   -7   -8\n",
      "    0   -3   -7   -6   -2   -5   -1  -11  -10   -6  -10   -4   -8   -8\n",
      "   -3   -2   -1   -4  -13   -2  -17    5   -5   -4   -4   -3  -21  -18\n",
      "    6  -20  -41  -14  -17  -24   -9  -10  -26  -13   -8    0   -8  -10]\n",
      "seed pixel in selected patch class 0\n",
      "[-155. -299.  345.  346.  390.  527.  611.  627.  620.  601.  568.  516.\n",
      "  479.  429.  402.  371.  351.  327.  306.  286.  263.  246.  231.  210.\n",
      "  188.  180.  169.  154.  152.  139.  139.  134.  137.  126.  120.  105.\n",
      "   86.   78.   66.   31.   38.   50.   55.   23.   41.   48.   43.   41.\n",
      "   37.   18.   19.   20.   33.   28.   27.   23.   17.   -1.  -15.  -17.\n",
      "  -19.  -86.  -92. -113.  -30.  -19.   -7.   -3.   -3.   -1.    0.   -2.\n",
      "    3.    2.    5.    0.   -3.   -3.  -17.  -45.  -56.  -51.  -68.  -67.\n",
      "  -56.  -16.  -16.  -21.  -20.  -34.  -24.  -18.  -15.  -10.   -8.  -14.\n",
      "   -8.    0.    7.    4.   -3.   -7.  -11.  -44.  -43.  -51.  -36.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  -17.  -36.\n",
      "  -23.   -7.   -2.   -7.   -6.    1.    1.   -1.    3.    3.    0.    3.\n",
      "   -1.    5.    9.   -2.    4.   -1.    3.    0.    0.   -2.    2.    0.\n",
      "    0.   -2.   -5.  -13.  -13.  -17.  -43.  -10.  -33.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  -14.  -10.  -10.   -9.   -6.  -31.  -31.  -15.   -7.   -4.  -14.   -6.\n",
      "   -7.   -8.    0.   -3.   -7.   -6.   -2.   -5.   -1.  -11.  -10.   -6.\n",
      "  -10.   -4.   -8.   -8.   -3.   -2.   -1.   -4.  -13.   -2.  -17.    5.\n",
      "   -5.   -4.   -4.   -3.  -21.  -18.    6.  -20.  -41.  -14.  -17.  -24.\n",
      "   -9.  -10.  -26.  -13.   -8.    0.   -8.  -10.]\n",
      "seed pixel in data class 1\n",
      "[-282 -541  389  433  461  603  670  680  653  618  575  534  491  475\n",
      "  459  424  412  395  381  359  341  325  319  297  283  285  273  267\n",
      "  266  264  262  259  250  249  247  242  231  237  242  233  246  257\n",
      "  265  263  288  288  287  286  300  294  300  318  330  331  334  327\n",
      "  326  296  252  233  222   70  -37  116  238  271  318  360  382  400\n",
      "  411  413  410  404  394  364  322  278  223  141 -207 -237  -80 -100\n",
      "   71  157  185  217  247  269  286  300  316  322  324  306  340  359\n",
      "  366  361  374  316  284  382  179  111    0    0    0    0    0    0\n",
      "    0    0 -249 -286  -56  -38  -55   25  105  162  214  252  290  362\n",
      "  343  362  374  389  390  402  392  398  394  397  372  363  342  323\n",
      "  299  269  254  246  198  196  163  138  118   93   59 -207    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  -31  -52    6   13   18   31   27   65   56   74   73   74   96  105\n",
      "  116  120  121  125  125  131  137  135  122  139  146  149  156  150\n",
      "  156  148  141  145  135  125  115  116  108  102  102   89   68   85\n",
      "   64   73   37   54   38   56   35   41   -3   20   10    7  -44    3]\n",
      "seed pixel in selected patch class 1\n",
      "[-282. -541.  389.  433.  461.  603.  670.  680.  653.  618.  575.  534.\n",
      "  491.  475.  459.  424.  412.  395.  381.  359.  341.  325.  319.  297.\n",
      "  283.  285.  273.  267.  266.  264.  262.  259.  250.  249.  247.  242.\n",
      "  231.  237.  242.  233.  246.  257.  265.  263.  288.  288.  287.  286.\n",
      "  300.  294.  300.  318.  330.  331.  334.  327.  326.  296.  252.  233.\n",
      "  222.   70.  -37.  116.  238.  271.  318.  360.  382.  400.  411.  413.\n",
      "  410.  404.  394.  364.  322.  278.  223.  141. -207. -237.  -80. -100.\n",
      "   71.  157.  185.  217.  247.  269.  286.  300.  316.  322.  324.  306.\n",
      "  340.  359.  366.  361.  374.  316.  284.  382.  179.  111.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0. -249. -286.  -56.  -38.  -55.   25.\n",
      "  105.  162.  214.  252.  290.  362.  343.  362.  374.  389.  390.  402.\n",
      "  392.  398.  394.  397.  372.  363.  342.  323.  299.  269.  254.  246.\n",
      "  198.  196.  163.  138.  118.   93.   59. -207.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  -31.  -52.    6.   13.   18.   31.   27.   65.   56.   74.   73.   74.\n",
      "   96.  105.  116.  120.  121.  125.  125.  131.  137.  135.  122.  139.\n",
      "  146.  149.  156.  150.  156.  148.  141.  145.  135.  125.  115.  116.\n",
      "  108.  102.  102.   89.   68.   85.   64.   73.   37.   54.   38.   56.\n",
      "   35.   41.   -3.   20.   10.    7.  -44.    3.]\n"
     ]
    }
   ],
   "source": [
    "# Generate validation data\n",
    "hsi_val = dataset[1]\n",
    "patch_size = 9\n",
    "sample_per_class = 100\n",
    "selected_patch_0, selected_patch_1, random_indices_0, random_indices_1 = CS.createSample(hsi_, patch_size, sample_per_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ded848cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 224, 9, 9])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])\n",
      "torch.Size([40])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "indices = random_indices_0 + random_indices_1\n",
    "\n",
    "# Concatenating along axis 0\n",
    "X_val = np.concatenate((selected_patch_0, selected_patch_1), axis=0)\n",
    "# Print shape to verify\n",
    "X_val = torch.tensor(X_val)\n",
    "X_val = X_val.to(torch.float32)\n",
    "X_val = X_val.permute(0, 3, 1, 2)\n",
    "print(X_val.shape)  # Expected output: (10, 9, 9, 224)\n",
    "\n",
    "\n",
    "y_val = np.array([])\n",
    "\n",
    "gt = hsi_val.gt\n",
    "for indice in indices:\n",
    "    y_val = np.append(y_val, gt[indice[0]][indice[1]])\n",
    "\n",
    "y_val = torch.tensor(y_val)\n",
    "y_val = y_val.to(torch.long)\n",
    "print(y_val)\n",
    "print(y_val.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c59b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0cc7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate datasets\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "val_dataset = CustomDataset(X_val, y_val)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 10\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Example: Fetching a batch from the training set\n",
    "for images, labels in train_loader:\n",
    "    print(f\"Training Batch - images shape: {images.shape}, labels shape: {labels.shape}\")\n",
    "    # break\n",
    "\n",
    "# Example: Fetching a batch from the validation set\n",
    "for images, labels in val_loader:\n",
    "    print(f\"Validation Batch - images shape: {images.shape}, labels shape: {labels.shape}\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62501ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd2d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 4:\n",
    "            last_loss = running_loss / 5 # loss  per 5 batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(train_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3d368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "    print(\"checkpoint 1: after training_one_epoch()\")\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    print(\"checkpoint 2: after model eval()\")\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(val_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(voutputs, 1)  # Get predicted class index\n",
    "            correct += (predicted == vlabels).sum().item()\n",
    "            total += vlabels.size(0)\n",
    "\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    print('LOSS train {} valid {} | Accuracy: {:.2f}%'.format(avg_loss, avg_vloss, accuracy))\n",
    "    print(\"checkpoint 3: after calculating loss and accuracy\")  \n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.add_scalar('Validation Accuracy', accuracy, epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = './models/model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fb1c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input):\n",
    "\n",
    "    with torch.no_grad():  # Disable gradients for inference\n",
    "        output = model(input)\n",
    "\n",
    "    # Convert logits to class label\n",
    "    predicted_class = torch.argmax(output, dim=1).item()\n",
    "    confidence = torch.nn.functional.softmax(output, dim=1)[0, predicted_class].item()\n",
    "\n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7013a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zeroPadding\n",
    "hsi_test = dataset[0]\n",
    "\n",
    "test_img = hsi_test.img\n",
    "test_gt = hsi_test.gt\n",
    "\n",
    "width = test_img.shape[0]\n",
    "height = test_img.shape[1]\n",
    "\n",
    "matrix=zeroPadding.zeroPadding_3D(test_img,half_patch) #add 0 in every side of the data\n",
    "print(test_img.shape)\n",
    "print(matrix.shape)\n",
    "print(f\"number of pixel {width * height}\")\n",
    "\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "test = 1\n",
    "break_flag = 0\n",
    "for i in range(width):\n",
    "    if break_flag == 1:\n",
    "        break\n",
    "    \n",
    "    for j in range(height):\n",
    "        if test > 10000:\n",
    "            print(\"break\")\n",
    "            break_flag = 1\n",
    "            break\n",
    "        x_pos = i\n",
    "        y_pos = j\n",
    "        selected_rows = matrix[range(x_pos,x_pos+2*half_patch+1), :]\n",
    "        testing_patch = selected_rows[:, range(y_pos, y_pos+2*half_patch+1)]\n",
    "\n",
    "        testing_patch = torch.tensor(testing_patch)\n",
    "        testing_patch = testing_patch.to(torch.float32)\n",
    "        testing_patch = testing_patch.unsqueeze(0)\n",
    "        testing_patch = testing_patch.permute(0, 3, 1, 2)\n",
    "\n",
    "        prediction, confidence = predict(testing_patch)\n",
    "\n",
    "        true_label = test_gt[i][j]\n",
    "\n",
    "        print(f\"{test}: {testing_patch.shape}: {prediction}, {confidence}, expecteed class: {true_label}\")\n",
    "\n",
    "        if(prediction == true_label):\n",
    "            correct += 1\n",
    "\n",
    "        test +=1\n",
    "        total += 1\n",
    "\n",
    "print(f\"{correct}/{total}\")\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98ed7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
