{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bfab266",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from HSI_class import HSI\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b718ca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg16\n",
    "import torch.nn as nn\n",
    "\n",
    "class VGG16_HSI(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(VGG16_HSI, self).__init__()\n",
    "\n",
    "         # Custom Convolutional Layer: Process 9x9x224 input\n",
    "        self.pre_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=224, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))  # Reduce to (256, 1, 1)\n",
    "        )\n",
    "\n",
    "        # Fully Connected Layer to reshape to (64, 56, 56)\n",
    "        self.fc = nn.Linear(256 * 1 * 1, 64 * 56 * 56)\n",
    "\n",
    "        # Load VGG-16 Model\n",
    "        self.encoder = vgg16(pretrained=False)\n",
    "\n",
    "        # Remove first VGG-16 conv layer\n",
    "        self.encoder.features = nn.Sequential(*list(self.encoder.features.children())[1:])\n",
    "\n",
    "        # Modify classifier to output 2 classes\n",
    "        self.encoder.classifier[6] = nn.Linear(4096, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(f'before {x.shape}')\n",
    "        x = self.pre_conv(x)  # Process hyperspectral input\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "\n",
    "        # print(f'after preconv {x.shape}')\n",
    "        x = self.fc(x)  # Fully connected layer\n",
    "        # print(f'after fc {x.shape}')\n",
    "        # Reshape to (batch_size, 64, 56, 56) before passing to VGG\n",
    "        x = x.view(x.size(0), 64, 56, 56)\n",
    "        # print(f'after reshape, before vgg second layer {x.shape}')\n",
    "\n",
    "        x = self.encoder.features(x)  # Pass to VGG-16\n",
    "        x = self.encoder.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.encoder.classifier(x)  # Final classification layer\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62fed078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus TUF\\Documents\\code\\TA\\myenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus TUF\\Documents\\code\\TA\\myenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Asus TUF\\AppData\\Local\\Temp\\ipykernel_7064\\3051421277.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PATH = r\"C:\\Users\\Asus TUF\\Documents\\code\\TA\\simsiam\\simsiam\\model_best.pth.tar\"\n",
    "\n",
    "\n",
    "print(\"creating model...\")\n",
    "saved_model = VGG16_HSI()\n",
    "checkpoint = torch.load(PATH)\n",
    "# print(checkpoint)\n",
    "saved_model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aca0a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM01.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM02.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM03.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM04.mat\n"
     ]
    }
   ],
   "source": [
    "dataset_path = r\"C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\"\n",
    "\n",
    "dataset = []\n",
    "\n",
    "i = 0\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if i > 3:\n",
    "        break\n",
    "    file_path = os.path.join(dataset_path, filename)\n",
    "    if os.path.isfile(file_path):  # Check if it's a file\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        hsi = HSI(file_path)\n",
    "        dataset.append(hsi)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c57e8cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape: (1386, 690, 224)\n",
      "img shape after padding (1394, 698, 224)\n",
      "number of pixel 956340\n"
     ]
    }
   ],
   "source": [
    "import zeroPadding\n",
    "hsi_test = dataset[2]\n",
    "\n",
    "test_img = hsi_test.img\n",
    "test_gt = hsi_test.gt\n",
    "\n",
    "patch_size = 9\n",
    "half_patch = patch_size // 2\n",
    "\n",
    "height = test_img.shape[0]\n",
    "width = test_img.shape[1]\n",
    "\n",
    "matrix=zeroPadding.zeroPadding_3D(test_img,half_patch) #add 0 in every side of the data\n",
    "print(f\"img shape: {test_img.shape}\")\n",
    "print(f\"img shape after padding {matrix.shape}\")\n",
    "print(f\"number of pixel {width * height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bad9508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input):\n",
    "\n",
    "    with torch.no_grad():  # Disable gradients for inference\n",
    "        output = saved_model(input)\n",
    "\n",
    "    # Convert logits to class label\n",
    "    predicted_class = torch.argmax(output, dim=1).item()\n",
    "    confidence = torch.nn.functional.softmax(output, dim=1)[0, predicted_class].item()\n",
    "\n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "214c70de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1386, 690)\n",
      "(916980, 2)\n",
      "(39360, 2)\n",
      "(200, 2)\n"
     ]
    }
   ],
   "source": [
    "print(test_gt.shape)\n",
    "\n",
    "indices0 = np.argwhere(test_gt == 0)\n",
    "indices1 = np.argwhere(test_gt == 1)\n",
    "\n",
    "print(indices0.shape)\n",
    "print(indices1.shape)\n",
    "\n",
    "num_samples = 100\n",
    "\n",
    "random_indices0 = indices0[np.random.choice(len(indices0), num_samples, replace=False)]\n",
    "random_indices1 = indices1[np.random.choice(len(indices1), num_samples, replace=False)]\n",
    "\n",
    "test_indices = np.vstack((random_indices0, random_indices1))\n",
    "\n",
    "print(test_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd6b1346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: prediction = 1, confidence: 1.0, expected: 0\n",
      "2: prediction = 1, confidence: 0.9999998807907104, expected: 0\n",
      "3: prediction = 1, confidence: 1.0, expected: 0\n",
      "4: prediction = 1, confidence: 1.0, expected: 0\n",
      "5: prediction = 1, confidence: 1.0, expected: 0\n",
      "6: prediction = 1, confidence: 0.9999955892562866, expected: 0\n",
      "7: prediction = 1, confidence: 1.0, expected: 0\n",
      "8: prediction = 1, confidence: 0.9999985694885254, expected: 0\n",
      "9: prediction = 1, confidence: 1.0, expected: 0\n",
      "10: prediction = 1, confidence: 1.0, expected: 0\n",
      "11: prediction = 1, confidence: 1.0, expected: 0\n",
      "12: prediction = 1, confidence: 1.0, expected: 0\n",
      "13: prediction = 1, confidence: 1.0, expected: 0\n",
      "14: prediction = 1, confidence: 1.0, expected: 0\n",
      "15: prediction = 1, confidence: 1.0, expected: 0\n",
      "16: prediction = 1, confidence: 1.0, expected: 0\n",
      "17: prediction = 1, confidence: 1.0, expected: 0\n",
      "18: prediction = 1, confidence: 1.0, expected: 0\n",
      "19: prediction = 1, confidence: 0.9999401569366455, expected: 0\n",
      "20: prediction = 1, confidence: 0.9999997615814209, expected: 0\n",
      "21: prediction = 1, confidence: 1.0, expected: 0\n",
      "22: prediction = 1, confidence: 0.9534116983413696, expected: 0\n",
      "23: prediction = 1, confidence: 1.0, expected: 0\n",
      "24: prediction = 1, confidence: 1.0, expected: 0\n",
      "25: prediction = 1, confidence: 1.0, expected: 0\n",
      "26: prediction = 1, confidence: 1.0, expected: 0\n",
      "27: prediction = 1, confidence: 1.0, expected: 0\n",
      "28: prediction = 1, confidence: 1.0, expected: 0\n",
      "29: prediction = 1, confidence: 1.0, expected: 0\n",
      "30: prediction = 1, confidence: 1.0, expected: 0\n",
      "31: prediction = 1, confidence: 1.0, expected: 0\n",
      "32: prediction = 1, confidence: 1.0, expected: 0\n",
      "33: prediction = 1, confidence: 1.0, expected: 0\n",
      "34: prediction = 1, confidence: 1.0, expected: 0\n",
      "35: prediction = 1, confidence: 1.0, expected: 0\n",
      "36: prediction = 1, confidence: 1.0, expected: 0\n",
      "37: prediction = 1, confidence: 1.0, expected: 0\n",
      "38: prediction = 1, confidence: 0.9999994039535522, expected: 0\n",
      "39: prediction = 1, confidence: 1.0, expected: 0\n",
      "40: prediction = 1, confidence: 1.0, expected: 0\n",
      "41: prediction = 1, confidence: 1.0, expected: 0\n",
      "42: prediction = 1, confidence: 1.0, expected: 0\n",
      "43: prediction = 1, confidence: 1.0, expected: 0\n",
      "44: prediction = 1, confidence: 1.0, expected: 0\n",
      "45: prediction = 1, confidence: 1.0, expected: 0\n",
      "46: prediction = 1, confidence: 1.0, expected: 0\n",
      "47: prediction = 1, confidence: 0.9999845027923584, expected: 0\n",
      "48: prediction = 1, confidence: 1.0, expected: 0\n",
      "49: prediction = 1, confidence: 1.0, expected: 0\n",
      "50: prediction = 1, confidence: 1.0, expected: 0\n",
      "51: prediction = 1, confidence: 1.0, expected: 0\n",
      "52: prediction = 1, confidence: 1.0, expected: 0\n",
      "53: prediction = 1, confidence: 1.0, expected: 0\n",
      "54: prediction = 1, confidence: 0.9999997615814209, expected: 0\n",
      "55: prediction = 1, confidence: 1.0, expected: 0\n",
      "56: prediction = 1, confidence: 1.0, expected: 0\n",
      "57: prediction = 1, confidence: 1.0, expected: 0\n",
      "58: prediction = 1, confidence: 1.0, expected: 0\n",
      "59: prediction = 1, confidence: 1.0, expected: 0\n",
      "60: prediction = 1, confidence: 1.0, expected: 0\n",
      "61: prediction = 1, confidence: 0.9999998807907104, expected: 0\n",
      "62: prediction = 1, confidence: 1.0, expected: 0\n",
      "63: prediction = 1, confidence: 1.0, expected: 0\n",
      "64: prediction = 1, confidence: 1.0, expected: 0\n",
      "65: prediction = 1, confidence: 1.0, expected: 0\n",
      "66: prediction = 1, confidence: 1.0, expected: 0\n",
      "67: prediction = 1, confidence: 1.0, expected: 0\n",
      "68: prediction = 1, confidence: 0.9999996423721313, expected: 0\n",
      "69: prediction = 1, confidence: 1.0, expected: 0\n",
      "70: prediction = 1, confidence: 1.0, expected: 0\n",
      "71: prediction = 1, confidence: 1.0, expected: 0\n",
      "72: prediction = 1, confidence: 1.0, expected: 0\n",
      "73: prediction = 1, confidence: 1.0, expected: 0\n",
      "74: prediction = 1, confidence: 1.0, expected: 0\n",
      "75: prediction = 1, confidence: 1.0, expected: 0\n",
      "76: prediction = 1, confidence: 1.0, expected: 0\n",
      "77: prediction = 1, confidence: 1.0, expected: 0\n",
      "78: prediction = 1, confidence: 1.0, expected: 0\n",
      "79: prediction = 1, confidence: 1.0, expected: 0\n",
      "80: prediction = 1, confidence: 1.0, expected: 0\n",
      "81: prediction = 1, confidence: 0.9999994039535522, expected: 0\n",
      "82: prediction = 1, confidence: 1.0, expected: 0\n",
      "83: prediction = 1, confidence: 0.9999997615814209, expected: 0\n",
      "84: prediction = 1, confidence: 1.0, expected: 0\n",
      "85: prediction = 1, confidence: 1.0, expected: 0\n",
      "86: prediction = 1, confidence: 0.9999996423721313, expected: 0\n",
      "87: prediction = 1, confidence: 0.9997438788414001, expected: 0\n",
      "88: prediction = 1, confidence: 0.9999916553497314, expected: 0\n",
      "89: prediction = 1, confidence: 1.0, expected: 0\n",
      "90: prediction = 1, confidence: 1.0, expected: 0\n",
      "91: prediction = 1, confidence: 1.0, expected: 0\n",
      "92: prediction = 1, confidence: 1.0, expected: 0\n",
      "93: prediction = 1, confidence: 1.0, expected: 0\n",
      "94: prediction = 1, confidence: 1.0, expected: 0\n",
      "95: prediction = 1, confidence: 1.0, expected: 0\n",
      "96: prediction = 1, confidence: 1.0, expected: 0\n",
      "97: prediction = 1, confidence: 1.0, expected: 0\n",
      "98: prediction = 1, confidence: 1.0, expected: 0\n",
      "99: prediction = 1, confidence: 1.0, expected: 0\n",
      "100: prediction = 1, confidence: 1.0, expected: 0\n",
      "101: prediction = 1, confidence: 1.0, expected: 1\n",
      "102: prediction = 1, confidence: 1.0, expected: 1\n",
      "103: prediction = 1, confidence: 0.9999998807907104, expected: 1\n",
      "104: prediction = 1, confidence: 0.9999994039535522, expected: 1\n",
      "105: prediction = 1, confidence: 1.0, expected: 1\n",
      "106: prediction = 1, confidence: 0.9999996423721313, expected: 1\n",
      "107: prediction = 1, confidence: 1.0, expected: 1\n",
      "108: prediction = 1, confidence: 0.9998867511749268, expected: 1\n",
      "109: prediction = 1, confidence: 1.0, expected: 1\n",
      "110: prediction = 1, confidence: 0.9999865293502808, expected: 1\n",
      "111: prediction = 1, confidence: 1.0, expected: 1\n",
      "112: prediction = 1, confidence: 1.0, expected: 1\n",
      "113: prediction = 1, confidence: 1.0, expected: 1\n",
      "114: prediction = 1, confidence: 1.0, expected: 1\n",
      "115: prediction = 1, confidence: 0.9999685287475586, expected: 1\n",
      "116: prediction = 1, confidence: 1.0, expected: 1\n",
      "117: prediction = 1, confidence: 1.0, expected: 1\n",
      "118: prediction = 1, confidence: 1.0, expected: 1\n",
      "119: prediction = 1, confidence: 1.0, expected: 1\n",
      "120: prediction = 1, confidence: 1.0, expected: 1\n",
      "121: prediction = 1, confidence: 0.9999997615814209, expected: 1\n",
      "122: prediction = 1, confidence: 1.0, expected: 1\n",
      "123: prediction = 1, confidence: 0.9998723268508911, expected: 1\n",
      "124: prediction = 1, confidence: 1.0, expected: 1\n",
      "125: prediction = 1, confidence: 0.9999998807907104, expected: 1\n",
      "126: prediction = 1, confidence: 1.0, expected: 1\n",
      "127: prediction = 1, confidence: 0.9999936819076538, expected: 1\n",
      "128: prediction = 1, confidence: 1.0, expected: 1\n",
      "129: prediction = 1, confidence: 1.0, expected: 1\n",
      "130: prediction = 1, confidence: 1.0, expected: 1\n",
      "131: prediction = 1, confidence: 1.0, expected: 1\n",
      "132: prediction = 1, confidence: 1.0, expected: 1\n",
      "133: prediction = 1, confidence: 1.0, expected: 1\n",
      "134: prediction = 1, confidence: 1.0, expected: 1\n",
      "135: prediction = 1, confidence: 1.0, expected: 1\n",
      "136: prediction = 1, confidence: 0.9999914169311523, expected: 1\n",
      "137: prediction = 1, confidence: 1.0, expected: 1\n",
      "138: prediction = 1, confidence: 0.999987006187439, expected: 1\n",
      "139: prediction = 1, confidence: 1.0, expected: 1\n",
      "140: prediction = 1, confidence: 1.0, expected: 1\n",
      "141: prediction = 1, confidence: 1.0, expected: 1\n",
      "142: prediction = 1, confidence: 1.0, expected: 1\n",
      "143: prediction = 1, confidence: 1.0, expected: 1\n",
      "144: prediction = 1, confidence: 0.9999970197677612, expected: 1\n",
      "145: prediction = 1, confidence: 1.0, expected: 1\n",
      "146: prediction = 1, confidence: 1.0, expected: 1\n",
      "147: prediction = 1, confidence: 1.0, expected: 1\n",
      "148: prediction = 1, confidence: 1.0, expected: 1\n",
      "149: prediction = 1, confidence: 1.0, expected: 1\n",
      "150: prediction = 1, confidence: 0.9999901056289673, expected: 1\n",
      "151: prediction = 1, confidence: 1.0, expected: 1\n",
      "152: prediction = 1, confidence: 1.0, expected: 1\n",
      "153: prediction = 1, confidence: 0.9999915361404419, expected: 1\n",
      "154: prediction = 1, confidence: 0.999998927116394, expected: 1\n",
      "155: prediction = 1, confidence: 1.0, expected: 1\n",
      "156: prediction = 1, confidence: 1.0, expected: 1\n",
      "157: prediction = 1, confidence: 0.9963656663894653, expected: 1\n",
      "158: prediction = 1, confidence: 1.0, expected: 1\n",
      "159: prediction = 1, confidence: 1.0, expected: 1\n",
      "160: prediction = 1, confidence: 1.0, expected: 1\n",
      "161: prediction = 1, confidence: 1.0, expected: 1\n",
      "162: prediction = 1, confidence: 1.0, expected: 1\n",
      "163: prediction = 1, confidence: 1.0, expected: 1\n",
      "164: prediction = 1, confidence: 1.0, expected: 1\n",
      "165: prediction = 1, confidence: 0.9999988079071045, expected: 1\n",
      "166: prediction = 1, confidence: 1.0, expected: 1\n",
      "167: prediction = 1, confidence: 1.0, expected: 1\n",
      "168: prediction = 1, confidence: 1.0, expected: 1\n",
      "169: prediction = 1, confidence: 1.0, expected: 1\n",
      "170: prediction = 1, confidence: 0.9999986886978149, expected: 1\n",
      "171: prediction = 1, confidence: 1.0, expected: 1\n",
      "172: prediction = 1, confidence: 1.0, expected: 1\n",
      "173: prediction = 1, confidence: 1.0, expected: 1\n",
      "174: prediction = 1, confidence: 1.0, expected: 1\n",
      "175: prediction = 1, confidence: 1.0, expected: 1\n",
      "176: prediction = 1, confidence: 1.0, expected: 1\n",
      "177: prediction = 1, confidence: 0.9999983310699463, expected: 1\n",
      "178: prediction = 1, confidence: 1.0, expected: 1\n",
      "179: prediction = 1, confidence: 1.0, expected: 1\n",
      "180: prediction = 1, confidence: 1.0, expected: 1\n",
      "181: prediction = 1, confidence: 1.0, expected: 1\n",
      "182: prediction = 1, confidence: 0.9999997615814209, expected: 1\n",
      "183: prediction = 1, confidence: 1.0, expected: 1\n",
      "184: prediction = 1, confidence: 1.0, expected: 1\n",
      "185: prediction = 1, confidence: 1.0, expected: 1\n",
      "186: prediction = 1, confidence: 1.0, expected: 1\n",
      "187: prediction = 1, confidence: 1.0, expected: 1\n",
      "188: prediction = 1, confidence: 1.0, expected: 1\n",
      "189: prediction = 1, confidence: 1.0, expected: 1\n",
      "190: prediction = 1, confidence: 1.0, expected: 1\n",
      "191: prediction = 1, confidence: 1.0, expected: 1\n",
      "192: prediction = 1, confidence: 0.9999992847442627, expected: 1\n",
      "193: prediction = 1, confidence: 0.9999996423721313, expected: 1\n",
      "194: prediction = 1, confidence: 1.0, expected: 1\n",
      "195: prediction = 1, confidence: 0.9999997615814209, expected: 1\n",
      "196: prediction = 1, confidence: 1.0, expected: 1\n",
      "197: prediction = 1, confidence: 0.9989607334136963, expected: 1\n",
      "198: prediction = 1, confidence: 1.0, expected: 1\n",
      "199: prediction = 1, confidence: 1.0, expected: 1\n",
      "200: prediction = 1, confidence: 0.9999997615814209, expected: 1\n",
      "skor: 100/200\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "i = 0\n",
    "for indice in test_indices:\n",
    "    x_pos = indice[0]\n",
    "    y_pos = indice[1]\n",
    "\n",
    "    true_label = test_gt[x_pos][y_pos]\n",
    "\n",
    "    selected_rows = matrix[range(x_pos,x_pos+2*half_patch+1), :]\n",
    "    testing_patch = selected_rows[:, range(y_pos, y_pos+2*half_patch+1)]\n",
    "    \n",
    "    # print(i)\n",
    "    # print(testing_patch[half_patch][half_patch])\n",
    "    # print(test_img[x_pos][y_pos])\n",
    "\n",
    "    testing_patch = torch.tensor(testing_patch)\n",
    "    testing_patch = testing_patch.to(torch.float32)\n",
    "    testing_patch = testing_patch.unsqueeze(0)\n",
    "    testing_patch = testing_patch.permute(0, 3, 1, 2)\n",
    "\n",
    "    prediction, confidence = predict(testing_patch)\n",
    "\n",
    "    print(f\"{i+1}: prediction = {prediction}, confidence: {confidence}, expected: {true_label}\")\n",
    "    \n",
    "    if(prediction == true_label):\n",
    "        correct += 1\n",
    "\n",
    "    total += 1\n",
    "    i += 1\n",
    "\n",
    "print(f\"skor: {correct}/{total}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
