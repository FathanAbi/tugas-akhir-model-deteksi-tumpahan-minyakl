{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import builtins\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torchvision.models import vgg16\n",
    "from HSI_class import HSI\n",
    "import createSample as CS\n",
    "import augmentation as aug\n",
    "\n",
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg16\n",
    "\n",
    "class VGG16_HSI(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(VGG16_HSI, self).__init__()\n",
    "\n",
    "         # Custom Convolutional Layer: Process 9x9x224 input\n",
    "        self.pre_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=224, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))  # Reduce to (256, 1, 1)\n",
    "        )\n",
    "\n",
    "        # Fully Connected Layer to reshape to (64, 56, 56)\n",
    "        self.fc = nn.Linear(256 * 1 * 1, 64 * 56 * 56)\n",
    "\n",
    "        # Load VGG-16 Model\n",
    "        self.encoder = vgg16(pretrained=False)\n",
    "\n",
    "        # Remove first VGG-16 conv layer\n",
    "        self.encoder.features = nn.Sequential(*list(self.encoder.features.children())[1:])\n",
    "\n",
    "        # Modify classifier to output 2 classes\n",
    "        self.encoder.classifier[6] = nn.Linear(4096, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(f'before {x.shape}')\n",
    "        x = self.pre_conv(x)  # Process hyperspectral input\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "\n",
    "        # print(f'after preconv {x.shape}')\n",
    "        x = self.fc(x)  # Fully connected layer\n",
    "        # print(f'after fc {x.shape}')\n",
    "        # Reshape to (batch_size, 64, 56, 56) before passing to VGG\n",
    "        x = x.view(x.size(0), 64, 56, 56)\n",
    "        # print(f'after reshape, before vgg second layer {x.shape}')\n",
    "\n",
    "        x = self.encoder.features(x)  # Pass to VGG-16\n",
    "        x = self.encoder.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.encoder.classifier(x)  # Final classification layer\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: 0 for training\n",
      "=> creating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus TUF\\Documents\\code\\TA\\myenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus TUF\\Documents\\code\\TA\\myenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16_HSI(\n",
      "  (pre_conv): Sequential(\n",
      "    (0): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=200704, bias=True)\n",
      "  (encoder): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): ReLU(inplace=True)\n",
      "      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU(inplace=True)\n",
      "      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (10): ReLU(inplace=True)\n",
      "      (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (12): ReLU(inplace=True)\n",
      "      (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (14): ReLU(inplace=True)\n",
      "      (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (16): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (17): ReLU(inplace=True)\n",
      "      (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (19): ReLU(inplace=True)\n",
      "      (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (21): ReLU(inplace=True)\n",
      "      (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (24): ReLU(inplace=True)\n",
      "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (26): ReLU(inplace=True)\n",
      "      (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (28): ReLU(inplace=True)\n",
      "      (29): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "gpu = 0\n",
    "\n",
    "print(\"Use GPU: {} for training\".format(gpu))\n",
    "\n",
    "print(\"=> creating model\")\n",
    "\n",
    "model = VGG16_HSI()\n",
    "\n",
    "print(model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_conv.0.weight: requires_grad=False\n",
      "pre_conv.0.bias: requires_grad=False\n",
      "pre_conv.2.weight: requires_grad=False\n",
      "pre_conv.2.bias: requires_grad=False\n",
      "pre_conv.3.weight: requires_grad=False\n",
      "pre_conv.3.bias: requires_grad=False\n",
      "pre_conv.5.weight: requires_grad=False\n",
      "pre_conv.5.bias: requires_grad=False\n",
      "fc.weight: requires_grad=False\n",
      "fc.bias: requires_grad=False\n",
      "encoder.features.1.weight: requires_grad=False\n",
      "encoder.features.1.bias: requires_grad=False\n",
      "encoder.features.4.weight: requires_grad=False\n",
      "encoder.features.4.bias: requires_grad=False\n",
      "encoder.features.6.weight: requires_grad=False\n",
      "encoder.features.6.bias: requires_grad=False\n",
      "encoder.features.9.weight: requires_grad=False\n",
      "encoder.features.9.bias: requires_grad=False\n",
      "encoder.features.11.weight: requires_grad=False\n",
      "encoder.features.11.bias: requires_grad=False\n",
      "encoder.features.13.weight: requires_grad=False\n",
      "encoder.features.13.bias: requires_grad=False\n",
      "encoder.features.16.weight: requires_grad=False\n",
      "encoder.features.16.bias: requires_grad=False\n",
      "encoder.features.18.weight: requires_grad=False\n",
      "encoder.features.18.bias: requires_grad=False\n",
      "encoder.features.20.weight: requires_grad=False\n",
      "encoder.features.20.bias: requires_grad=False\n",
      "encoder.features.23.weight: requires_grad=False\n",
      "encoder.features.23.bias: requires_grad=False\n",
      "encoder.features.25.weight: requires_grad=False\n",
      "encoder.features.25.bias: requires_grad=False\n",
      "encoder.features.27.weight: requires_grad=False\n",
      "encoder.features.27.bias: requires_grad=False\n",
      "encoder.classifier.0.weight: requires_grad=False\n",
      "encoder.classifier.0.bias: requires_grad=False\n",
      "encoder.classifier.3.weight: requires_grad=False\n",
      "encoder.classifier.3.bias: requires_grad=False\n",
      "encoder.classifier.6.weight: requires_grad=True\n",
      "encoder.classifier.6.bias: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "# Freeze all layers except the last fully connected layer\n",
    "for param in model.pre_conv.parameters():\n",
    "    param.requires_grad = False  # Freeze convolutional layers\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = False  # Freeze convolutional layers\n",
    "for param in model.encoder.features.parameters():\n",
    "    param.requires_grad = False  # Freeze convolutional layers\n",
    "\n",
    "for param in model.encoder.classifier[:-1].parameters():\n",
    "    param.requires_grad = False  # Freeze all but the last FC layer\n",
    "\n",
    "# Initialize the last FC layer\n",
    "# Initialize the last FC layer\n",
    "torch.nn.init.normal_(model.encoder.classifier[6].weight, mean=0.0, std=0.01)\n",
    "torch.nn.init.zeros_(model.encoder.classifier[6].bias)\n",
    "\n",
    "# Check which layers are trainable\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'C:\\Users\\Asus TUF\\Documents\\code\\TA\\simsiam\\simsiam\\models\\checkpoint_0024.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus TUF\\AppData\\Local\\Temp\\ipykernel_2604\\493847072.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(pretrained, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state_dict keys: odict_keys(['pre_conv.0.weight', 'pre_conv.0.bias', 'pre_conv.2.weight', 'pre_conv.2.bias', 'pre_conv.2.running_mean', 'pre_conv.2.running_var', 'pre_conv.2.num_batches_tracked', 'pre_conv.3.weight', 'pre_conv.3.bias', 'pre_conv.5.weight', 'pre_conv.5.bias', 'pre_conv.5.running_mean', 'pre_conv.5.running_var', 'pre_conv.5.num_batches_tracked', 'fc.weight', 'fc.bias', 'encoder.features.1.weight', 'encoder.features.1.bias', 'encoder.features.4.weight', 'encoder.features.4.bias', 'encoder.features.6.weight', 'encoder.features.6.bias', 'encoder.features.9.weight', 'encoder.features.9.bias', 'encoder.features.11.weight', 'encoder.features.11.bias', 'encoder.features.13.weight', 'encoder.features.13.bias', 'encoder.features.16.weight', 'encoder.features.16.bias', 'encoder.features.18.weight', 'encoder.features.18.bias', 'encoder.features.20.weight', 'encoder.features.20.bias', 'encoder.features.23.weight', 'encoder.features.23.bias', 'encoder.features.25.weight', 'encoder.features.25.bias', 'encoder.features.27.weight', 'encoder.features.27.bias', 'encoder.classifier.0.weight', 'encoder.classifier.0.bias', 'encoder.classifier.3.weight', 'encoder.classifier.3.bias', 'encoder.classifier.6.weight', 'encoder.classifier.6.bias'])\n",
      "Checkpoint state_dict keys: odict_keys(['pre_conv.0.weight', 'pre_conv.0.bias', 'pre_conv.2.weight', 'pre_conv.2.bias', 'pre_conv.2.running_mean', 'pre_conv.2.running_var', 'pre_conv.2.num_batches_tracked', 'pre_conv.3.weight', 'pre_conv.3.bias', 'pre_conv.5.weight', 'pre_conv.5.bias', 'pre_conv.5.running_mean', 'pre_conv.5.running_var', 'pre_conv.5.num_batches_tracked', 'fc.weight', 'fc.bias', 'encoder.features.1.weight', 'encoder.features.1.bias', 'encoder.features.4.weight', 'encoder.features.4.bias', 'encoder.features.6.weight', 'encoder.features.6.bias', 'encoder.features.9.weight', 'encoder.features.9.bias', 'encoder.features.11.weight', 'encoder.features.11.bias', 'encoder.features.13.weight', 'encoder.features.13.bias', 'encoder.features.16.weight', 'encoder.features.16.bias', 'encoder.features.18.weight', 'encoder.features.18.bias', 'encoder.features.20.weight', 'encoder.features.20.bias', 'encoder.features.23.weight', 'encoder.features.23.bias', 'encoder.features.25.weight', 'encoder.features.25.bias', 'encoder.features.27.weight', 'encoder.features.27.bias', 'encoder.classifier.0.weight', 'encoder.classifier.0.bias', 'encoder.classifier.3.weight', 'encoder.classifier.3.bias', 'encoder.classifier.6.weight', 'encoder.classifier.6.bias', 'projector.0.weight', 'projector.1.weight', 'projector.1.bias', 'projector.1.running_mean', 'projector.1.running_var', 'projector.1.num_batches_tracked', 'projector.3.weight', 'projector.4.weight', 'projector.4.bias', 'projector.4.running_mean', 'projector.4.running_var', 'projector.4.num_batches_tracked', 'projector.6.running_mean', 'projector.6.running_var', 'projector.6.num_batches_tracked', 'predictor.0.weight', 'predictor.1.weight', 'predictor.1.bias', 'predictor.1.running_mean', 'predictor.1.running_var', 'predictor.1.num_batches_tracked', 'predictor.3.weight', 'predictor.3.bias'])\n",
      "Missing keys: ['encoder.classifier.6.weight', 'encoder.classifier.6.bias']\n",
      "=> loaded pre-trained model 'C:\\Users\\Asus TUF\\Documents\\code\\TA\\simsiam\\simsiam\\models\\checkpoint_0024.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "pretrained = r'C:\\Users\\Asus TUF\\Documents\\code\\TA\\simsiam\\simsiam\\models\\checkpoint_0024.pth.tar'\n",
    "\n",
    "if pretrained:\n",
    "    if os.path.isfile(pretrained):\n",
    "        print(\"=> loading checkpoint '{}'\".format(pretrained))\n",
    "        checkpoint = torch.load(pretrained, map_location=\"cpu\")\n",
    "\n",
    "        # rename moco pre-trained keys\n",
    "        state_dict = checkpoint['state_dict']\n",
    "\n",
    "        print(\"Model state_dict keys:\", model.state_dict().keys())  # Debugging\n",
    "        print(\"Checkpoint state_dict keys:\", state_dict.keys())  \n",
    "        # for k in list(state_dict.keys()):\n",
    "        #     print(f\"Processing key: {k}\")  # Debugging\n",
    "        #     if k.startswith('module.encoder') and not k.startswith('module.encoder.fc'):\n",
    "        #         state_dict[k[len(\"module.encoder.\"):]] = state_dict[k]\n",
    "        #     del state_dict[k]\n",
    "\n",
    "        # Remove the final classification layer from state_dict\n",
    "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"encoder.classifier.6\")}\n",
    "\n",
    "        # Load the modified state_dict (ignoring the missing classification layer)\n",
    "        msg = model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "        # Check missing keys\n",
    "        print(\"Missing keys:\", msg.missing_keys)\n",
    "\n",
    "        start_epoch = 0\n",
    "        msg = model.load_state_dict(state_dict, strict=False)\n",
    "  \n",
    "        assert set(msg.missing_keys) == {\"encoder.classifier.6.weight\", \"encoder.classifier.6.bias\"}\n",
    "\n",
    "        print(\"=> loaded pre-trained model '{}'\".format(pretrained))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(pretrained))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16_HSI(\n",
      "  (pre_conv): Sequential(\n",
      "    (0): Conv2d(224, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=200704, bias=True)\n",
      "  (encoder): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): ReLU(inplace=True)\n",
      "      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU(inplace=True)\n",
      "      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (10): ReLU(inplace=True)\n",
      "      (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (12): ReLU(inplace=True)\n",
      "      (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (14): ReLU(inplace=True)\n",
      "      (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (16): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (17): ReLU(inplace=True)\n",
      "      (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (19): ReLU(inplace=True)\n",
      "      (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (21): ReLU(inplace=True)\n",
      "      (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (24): ReLU(inplace=True)\n",
      "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (26): ReLU(inplace=True)\n",
      "      (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (28): ReLU(inplace=True)\n",
      "      (29): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM01.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM02.mat\n",
      "hsi shape\n",
      "(1243, 684, 224)\n",
      "creating 5 Randomly chosen 0 indices:\n",
      "creating 5 Randomly chosen 1 indices:\n",
      "[-177 -354  262  312  346  476  553  574  557  547  523  474  429  394\n",
      "  370  336  313  289  270  243  215  199  177  149  128  115  104   92\n",
      "   83   76   75   69   66   64   56   42   28   23   12  -30   -4   16\n",
      "   26  -13    7   16    9   11    7  -14   -2   -4   16   11   12    9\n",
      "    6   -9  -18  -21  -21  -80  -82  -93  -21   -7    1    8    5    9\n",
      "   15    9   10   10   10    6    3    2   -8  -35  -52  -44  -58  -58\n",
      "  -40   -8   -2   -4   -3  -13   -1    0    8   11   10   19   10    3\n",
      "   -2    7   -1    8    1   42  -32  -68  -36    0    0    0    0    0\n",
      "    0    0    0    0    0    0  -12  -28   -8   -7   -2    0    4    3\n",
      "    8   13    6   11    8    9   10   16    3    6    1    7    6    4\n",
      "    5   10    9    4   -4    1    1    3    0   -5   -7  -10  -33    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  -14  -10  -17   -4   -6  -24  -31   -3    3    3    4    0    8    0\n",
      "    3    6    6    0   -2    7    5    3    5    5    2    0    0    4\n",
      "    0    1    7    0   10   -2    8   -5    9   -4   -4   -3   -7  -12\n",
      "  -18  -12  -23   -3  -10  -24   -9   -6  -15   -8   -8  -11   -8  -10]\n",
      "[-177. -354.  262.  312.  346.  476.  553.  574.  557.  547.  523.  474.\n",
      "  429.  394.  370.  336.  313.  289.  270.  243.  215.  199.  177.  149.\n",
      "  128.  115.  104.   92.   83.   76.   75.   69.   66.   64.   56.   42.\n",
      "   28.   23.   12.  -30.   -4.   16.   26.  -13.    7.   16.    9.   11.\n",
      "    7.  -14.   -2.   -4.   16.   11.   12.    9.    6.   -9.  -18.  -21.\n",
      "  -21.  -80.  -82.  -93.  -21.   -7.    1.    8.    5.    9.   15.    9.\n",
      "   10.   10.   10.    6.    3.    2.   -8.  -35.  -52.  -44.  -58.  -58.\n",
      "  -40.   -8.   -2.   -4.   -3.  -13.   -1.    0.    8.   11.   10.   19.\n",
      "   10.    3.   -2.    7.   -1.    8.    1.   42.  -32.  -68.  -36.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  -12.  -28.\n",
      "   -8.   -7.   -2.    0.    4.    3.    8.   13.    6.   11.    8.    9.\n",
      "   10.   16.    3.    6.    1.    7.    6.    4.    5.   10.    9.    4.\n",
      "   -4.    1.    1.    3.    0.   -5.   -7.  -10.  -33.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  -14.  -10.  -17.   -4.   -6.  -24.  -31.   -3.    3.    3.    4.    0.\n",
      "    8.    0.    3.    6.    6.    0.   -2.    7.    5.    3.    5.    5.\n",
      "    2.    0.    0.    4.    0.    1.    7.    0.   10.   -2.    8.   -5.\n",
      "    9.   -4.   -4.   -3.   -7.  -12.  -18.  -12.  -23.   -3.  -10.  -24.\n",
      "   -9.   -6.  -15.   -8.   -8.  -11.   -8.  -10.]\n",
      "[-291 -379  341  405  457  576  636  639  599  553  514  452  423  395\n",
      "  373  349  336  314  297  282  274  257  254  253  243  238  239  235\n",
      "  236  237  238  242  225  233  228  217  220  223  229  222  230  245\n",
      "  256  255  279  284  285  289  303  304  314  329  341  345  352  348\n",
      "  355  323  292  270  264  188  106  234  321  345  381  425  458  476\n",
      "  496  501  501  495  486  461  413  360  312  242  -98 -183   20   -2\n",
      "  169  237  273  306  352  378  403  423  436  449  465  479  491  499\n",
      "  500  487  470  424  386  350  285  238    0    0    0    0    0    0\n",
      "    0    0  -81 -116  -56   19  -16   98  139  205  253  300  332  367\n",
      "  386  416  424  447  451  458  458  463  470  466  455  430  411  396\n",
      "  365  327  293  287  239  234  215  182  177  158  115  -12    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  -12  -81   14   16   21   39   77   52   73   93  107  111  137  150\n",
      "  155  163  163  172  177  182  184  182  177  189  202  202  205  201\n",
      "  199  192  179  172  151  141  115  116   96   96   91   84   75   65\n",
      "   64   73   57   47   38   56   35   18   10   -2   24  -29  -20    3]\n",
      "[-291. -379.  341.  405.  457.  576.  636.  639.  599.  553.  514.  452.\n",
      "  423.  395.  373.  349.  336.  314.  297.  282.  274.  257.  254.  253.\n",
      "  243.  238.  239.  235.  236.  237.  238.  242.  225.  233.  228.  217.\n",
      "  220.  223.  229.  222.  230.  245.  256.  255.  279.  284.  285.  289.\n",
      "  303.  304.  314.  329.  341.  345.  352.  348.  355.  323.  292.  270.\n",
      "  264.  188.  106.  234.  321.  345.  381.  425.  458.  476.  496.  501.\n",
      "  501.  495.  486.  461.  413.  360.  312.  242.  -98. -183.   20.   -2.\n",
      "  169.  237.  273.  306.  352.  378.  403.  423.  436.  449.  465.  479.\n",
      "  491.  499.  500.  487.  470.  424.  386.  350.  285.  238.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.  -81. -116.  -56.   19.  -16.   98.\n",
      "  139.  205.  253.  300.  332.  367.  386.  416.  424.  447.  451.  458.\n",
      "  458.  463.  470.  466.  455.  430.  411.  396.  365.  327.  293.  287.\n",
      "  239.  234.  215.  182.  177.  158.  115.  -12.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  -12.  -81.   14.   16.   21.   39.   77.   52.   73.   93.  107.  111.\n",
      "  137.  150.  155.  163.  163.  172.  177.  182.  184.  182.  177.  189.\n",
      "  202.  202.  205.  201.  199.  192.  179.  172.  151.  141.  115.  116.\n",
      "   96.   96.   91.   84.   75.   65.   64.   73.   57.   47.   38.   56.\n",
      "   35.   18.   10.   -2.   24.  -29.  -20.    3.]\n"
     ]
    }
   ],
   "source": [
    "dataset_path = r\"C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\"\n",
    "\n",
    "dataset = []\n",
    "\n",
    "i = 0\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if i > 1:\n",
    "        break\n",
    "    file_path = os.path.join(dataset_path, filename)\n",
    "    if os.path.isfile(file_path):  # Check if it's a file\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        hsi = HSI(file_path)\n",
    "        dataset.append(hsi)\n",
    "    i += 1\n",
    "hsi_ = dataset[0]\n",
    "patch_size = 9\n",
    "sample_per_class = 5\n",
    "selected_patch_0, selected_patch_1, random_indices_0, random_indices_1 = CS.createSample(hsi_, patch_size, sample_per_class)\n",
    "\n",
    "i =0\n",
    "half_patch = patch_size // 2\n",
    "print(hsi_.img[random_indices_0[i][0]][random_indices_0[i][1]])\n",
    "print(selected_patch_0[i][half_patch][half_patch])\n",
    "\n",
    "print(hsi_.img[random_indices_1[i][0]][random_indices_1[i][1]])\n",
    "print(selected_patch_1[i][half_patch][half_patch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of element equal 0 5\n",
      "number of element equal 1 5\n",
      "x_train shape: (10, 9, 9, 224)\n",
      "y_train shape: (10,)\n"
     ]
    }
   ],
   "source": [
    "indices = random_indices_0 +  random_indices_1\n",
    "\n",
    "# Concatenating along axis 0\n",
    "x_train = np.concatenate((selected_patch_0, selected_patch_1), )\n",
    "\n",
    "y_train = np.array([])\n",
    "\n",
    "gt = hsi_.gt\n",
    "for indice in indices:\n",
    "    # print(gt[indice[0]][indice[1]])\n",
    "    y_train = np.append(y_train, gt[indice[0]][indice[1]])\n",
    "\n",
    "count = np.count_nonzero(y_train == 0)  # Count elements equal to 0\n",
    "print(f'number of element equal 0 {count}')\n",
    "\n",
    "count = np.count_nonzero(y_train == 1)  # Count elements equal to 1\n",
    "print(f'number of element equal 1 {count}')\n",
    "\n",
    "\n",
    "\n",
    "# Print shape to verify\n",
    "print(f\"x_train shape: {x_train.shape}\")  # Expected output: (10, 9, 9, 224)\n",
    "print(f\"y_train shape: {y_train.shape}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j:  100\n",
      "hasil augmentasi 1 shape: (100, 9, 9, 224)\n",
      "label augmentai 1 shape: (100,)\n",
      "hasil augmentasi 2 shape: (400, 9, 9, 224)\n",
      "label augmentasi 2 shape: (400,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Element 0 occurs 50 times.\n",
      "Element 1 occurs 50 times.\n",
      "Element 0 occurs 200 times.\n",
      "Element 1 occurs 200 times.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "n_category = 2\n",
    "band_size = 224\n",
    "num_per_category = 50\n",
    "\n",
    "data_augment1, label_augment1 = aug.Augment_data(x_train, y_train, n_category, patch_size, band_size, num_per_category)\n",
    "\n",
    "data_augment2, label_augment2 = aug.Augment_data2(x_train, y_train, n_category, patch_size, band_size, 200)\n",
    "\n",
    "print(f\"hasil augmentasi 1 shape: {data_augment1.shape}\")\n",
    "print(f\"label augmentai 1 shape: {label_augment1.shape}\")\n",
    "\n",
    "print(f\"hasil augmentasi 2 shape: {data_augment2.shape}\")\n",
    "print(f\"label augmentasi 2 shape: {label_augment2.shape}\")\n",
    "\n",
    "print(label_augment1)\n",
    "print(label_augment2)\n",
    "\n",
    "# Count occurrences of each unique element\n",
    "counts1 = np.bincount(label_augment1)\n",
    "\n",
    "# Print results\n",
    "for i, count in enumerate(counts1):\n",
    "    print(f\"Element {i} occurs {count} times.\")\n",
    "\n",
    "counts2 = np.bincount(label_augment2)\n",
    "\n",
    "# Print results\n",
    "for i, count in enumerate(counts2):\n",
    "    print(f\"Element {i} occurs {count} times.\")\n",
    "\n",
    "print(label_augment1[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hasil augmentasi gabungan untuk training: (500, 9, 9, 224)\n",
      "label augmentasi gabungan: (500,)\n",
      "Element 0 occurs 250 times.\n",
      "Element 1 occurs 250 times.\n"
     ]
    }
   ],
   "source": [
    "data_augment = np.concatenate((data_augment1, data_augment2))\n",
    "label_augment = np.concatenate((label_augment1, label_augment2))\n",
    "\n",
    "print(f\"hasil augmentasi gabungan untuk training: {data_augment.shape}\")\n",
    "print(f\"label augmentasi gabungan: {label_augment.shape}\")\n",
    "\n",
    "# print(label_augment)\n",
    "\n",
    "# Count occurrences of each unique element\n",
    "counts = np.bincount(label_augment)\n",
    "\n",
    "# Print results\n",
    "for i, count in enumerate(counts):\n",
    "    print(f\"Element {i} occurs {count} times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([1, 224, 9, 9])\n",
      "input2 shape: torch.Size([1, 224, 9, 9])\n",
      "tensor([[-0.0478, -0.0908]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test = data_augment[0]\n",
    "test = torch.tensor(test)\n",
    "test = test.to(torch.float32)\n",
    "test = test.unsqueeze(0)\n",
    "\n",
    "input = test\n",
    "input = input.permute(0, 3, 1, 2)\n",
    "\n",
    "test2 = data_augment[1]\n",
    "test2 = torch.tensor(test2)\n",
    "test2 = test2.to(torch.float32)\n",
    "test2 = test2.unsqueeze(0)\n",
    "\n",
    "input2 = test2\n",
    "input2 = input2.permute(0, 3, 1, 2)\n",
    "\n",
    "print(f\"input shape: {input.shape}\")\n",
    "print(f\"input2 shape: {input2.shape}\")\n",
    "\n",
    "# Pass the input through the model\n",
    "model.eval()\n",
    "output = model(input)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "batch_size = 50\n",
    "momentum = 0.9\n",
    "weight_decay = 0\n",
    "\n",
    "init_lr = lr * batch_size / 256\n",
    "\n",
    "torch.cuda.set_device(gpu)\n",
    "model = model.cuda(gpu)\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "\n",
    "# optimize only the linear classifier\n",
    "parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "assert len(parameters) == 2  # fc.weight, fc.bias\n",
    "\n",
    "optimizer = torch.optim.SGD(parameters, init_lr,\n",
    "                            momentum=momentum,\n",
    "                            weight_decay=weight_decay)\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 9, 9, 224)\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "augmentation = [\n",
    "    transforms.RandomHorizontalFlip(),  # Flip along width\n",
    "    transforms.RandomVerticalFlip(),    # Flip along height\n",
    "    transforms.RandomRotation(20),      # Rotate image slightly\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize hyperspectral data\n",
    "]\n",
    "\n",
    "transform = transforms.Compose(augmentation)\n",
    "\n",
    "print(data_augment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([500, 224, 9, 9])\n",
      "Train shape: torch.Size([400, 224, 9, 9]), Validation shape: torch.Size([100, 224, 9, 9])\n",
      "tes\n",
      "tes2\n",
      "torch.Size([50])\n",
      "Train loader size: 8, Validation loader size: 2\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images (Tensor or list of Tensors): Preloaded images of shape (N, 9, 9, 224)\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "        \"\"\"\n",
    "        self.images = images  # Assuming it's a list or tensor\n",
    "        self.transform = transform\n",
    "        self.label = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        label = self.label[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img1 = self.transform(img)  # First augmentation\n",
    "        \n",
    "            return img1, label  # Return both augmented versions\n",
    "        \n",
    "        return img, label  # If no transform is provided, return the original image twice\n",
    "\n",
    "\n",
    "# Example usage\n",
    "preloaded_images = data_augment  # Example tensor with 100 images\n",
    "X = torch.tensor(preloaded_images)\n",
    "X= X.to(torch.float32)\n",
    "X = X.permute(0, 3, 1, 2)\n",
    "print(f\"X_train shape: {X.shape}\")\n",
    "\n",
    "y = torch.tensor(label_augment)\n",
    "\n",
    "# Define transformations if needed\n",
    "transform = transforms.Compose(augmentation)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Train shape: {X_train.shape}, Validation shape: {X_val.shape}\")\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train, transform=transform)\n",
    "val_dataset = CustomDataset(X_val, y_val, transform=transform)\n",
    "\n",
    "train_sampler = None\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True, drop_last=True)\n",
    "\n",
    "# 7. Check Output\n",
    "print(\"tes\")\n",
    "batch1 = next(iter(train_loader))\n",
    "print(\"tes2\")\n",
    "print(batch1[1].size())\n",
    "print(f\"Train loader size: {len(train_loader)}, Validation loader size: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    \"\"\"\n",
    "    Switch to eval mode:\n",
    "    Under the protocol of linear classification on frozen features/models,\n",
    "    it is not legitimate to change any part of the pre-trained model.\n",
    "    BatchNorm in train mode may revise running mean/std (even if it receives\n",
    "    no gradient), which are part of the model parameters too.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        gpu = 0\n",
    "        images = images.cuda(gpu, non_blocking=True)\n",
    "        target = target.cuda(gpu, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, = accuracy(output, target, topk=(1,))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        print_freq = 10\n",
    "        if i % print_freq == 0:\n",
    "            progress.display(i)\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            gpu = 0\n",
    "            images = images.cuda(gpu, non_blocking=True)\n",
    "            target = target.cuda(gpu, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, = accuracy(output, target, topk=(1,))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            # top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            print_freq = 10\n",
    "            if i % print_freq == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='models/checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "def sanity_check(state_dict, pretrained_weights):\n",
    "    \"\"\"\n",
    "    Linear classifier should not change any weights other than the linear layer.\n",
    "    This sanity check asserts nothing wrong happens (e.g., BN stats updated).\n",
    "    \"\"\"\n",
    "    print(\"=> loading '{}' for sanity check\".format(pretrained_weights))\n",
    "    checkpoint = torch.load(pretrained_weights, map_location=\"cpu\")\n",
    "    state_dict_pre = checkpoint['state_dict']\n",
    "\n",
    "    for k in list(state_dict.keys()):\n",
    "        # Ignore fc layer\n",
    "        if 'fc.weight' in k or 'fc.bias' in k:\n",
    "            continue\n",
    "\n",
    "        # Adjust key mapping to match checkpoint format\n",
    "        k_pre = k.replace('module.encoder.', '')  # Remove unnecessary prefix\n",
    "\n",
    "        # Skip missing keys\n",
    "        if k_pre not in state_dict_pre:\n",
    "            print(f\"Warning: {k_pre} not found in pretrained model. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Check if tensor shapes match before comparing values\n",
    "        if state_dict[k].shape != state_dict_pre[k_pre].shape:\n",
    "            print(f\"Warning: Shape mismatch for {k}: {state_dict[k].shape} vs {state_dict_pre[k_pre].shape}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Assert that the weights remain unchanged\n",
    "        assert ((state_dict[k].cpu() == state_dict_pre[k_pre]).all()), \\\n",
    "            '{} is changed in linear classifier training.'.format(k)\n",
    "\n",
    "    print(\"=> sanity check passed.\")\n",
    "\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, init_lr, epoch, epochs):\n",
    "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
    "    cur_lr = init_lr * 0.5 * (1. + math.cos(math.pi * epoch / epochs))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = cur_lr\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_conv.0.weight: requires_grad=False\n",
      "pre_conv.0.bias: requires_grad=False\n",
      "pre_conv.2.weight: requires_grad=False\n",
      "pre_conv.2.bias: requires_grad=False\n",
      "pre_conv.3.weight: requires_grad=False\n",
      "pre_conv.3.bias: requires_grad=False\n",
      "pre_conv.5.weight: requires_grad=False\n",
      "pre_conv.5.bias: requires_grad=False\n",
      "fc.weight: requires_grad=False\n",
      "fc.bias: requires_grad=False\n",
      "encoder.features.1.weight: requires_grad=False\n",
      "encoder.features.1.bias: requires_grad=False\n",
      "encoder.features.4.weight: requires_grad=False\n",
      "encoder.features.4.bias: requires_grad=False\n",
      "encoder.features.6.weight: requires_grad=False\n",
      "encoder.features.6.bias: requires_grad=False\n",
      "encoder.features.9.weight: requires_grad=False\n",
      "encoder.features.9.bias: requires_grad=False\n",
      "encoder.features.11.weight: requires_grad=False\n",
      "encoder.features.11.bias: requires_grad=False\n",
      "encoder.features.13.weight: requires_grad=False\n",
      "encoder.features.13.bias: requires_grad=False\n",
      "encoder.features.16.weight: requires_grad=False\n",
      "encoder.features.16.bias: requires_grad=False\n",
      "encoder.features.18.weight: requires_grad=False\n",
      "encoder.features.18.bias: requires_grad=False\n",
      "encoder.features.20.weight: requires_grad=False\n",
      "encoder.features.20.bias: requires_grad=False\n",
      "encoder.features.23.weight: requires_grad=False\n",
      "encoder.features.23.bias: requires_grad=False\n",
      "encoder.features.25.weight: requires_grad=False\n",
      "encoder.features.25.bias: requires_grad=False\n",
      "encoder.features.27.weight: requires_grad=False\n",
      "encoder.features.27.bias: requires_grad=False\n",
      "encoder.classifier.0.weight: requires_grad=False\n",
      "encoder.classifier.0.bias: requires_grad=False\n",
      "encoder.classifier.3.weight: requires_grad=False\n",
      "encoder.classifier.3.bias: requires_grad=False\n",
      "encoder.classifier.6.weight: requires_grad=True\n",
      "encoder.classifier.6.bias: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "# Freeze all layers except the last fully connected layer\n",
    "for param in model.pre_conv.parameters():\n",
    "    param.requires_grad = False  # Freeze convolutional layers\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = False  # Freeze convolutional layers\n",
    "for param in model.encoder.features.parameters():\n",
    "    param.requires_grad = False  # Freeze convolutional layers\n",
    "\n",
    "for param in model.encoder.classifier[:-1].parameters():\n",
    "    param.requires_grad = False  # Freeze all but the last FC layer\n",
    "\n",
    "# Initialize the last FC layer\n",
    "# Initialize the last FC layer\n",
    "torch.nn.init.normal_(model.encoder.classifier[6].weight, mean=0.0, std=0.01)\n",
    "torch.nn.init.zeros_(model.encoder.classifier[6].bias)\n",
    "\n",
    "# Check which layers are trainable\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/8]\tTime  1.464 ( 1.464)\tData  0.140 ( 0.140)\tLoss 8.2532e-01 (8.2532e-01)\tAcc@1  38.00 ( 38.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.164 ( 0.164)\tLoss 4.2141e+00 (4.2141e+00)\tAcc@1  56.00 ( 56.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 51.000 Acc@5 0.000\n",
      "=> loading 'C:\\Users\\Asus TUF\\Documents\\code\\TA\\simsiam\\simsiam\\models\\checkpoint_0024.pth.tar' for sanity check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus TUF\\AppData\\Local\\Temp\\ipykernel_2604\\513101894.py:111: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(pretrained_weights, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Shape mismatch for encoder.classifier.6.weight: torch.Size([2, 4096]) vs torch.Size([2048, 4096]). Skipping...\n",
      "Warning: Shape mismatch for encoder.classifier.6.bias: torch.Size([2]) vs torch.Size([2048]). Skipping...\n",
      "=> sanity check passed.\n",
      "Epoch: [1][0/8]\tTime  0.508 ( 0.508)\tData  0.418 ( 0.418)\tLoss 4.0642e+00 (4.0642e+00)\tAcc@1  50.00 ( 50.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.170 ( 0.170)\tLoss 1.3430e+00 (1.3430e+00)\tAcc@1  82.00 ( 82.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 85.000 Acc@5 0.000\n",
      "Epoch: [2][0/8]\tTime  0.224 ( 0.224)\tData  0.076 ( 0.076)\tLoss 1.3169e+00 (1.3169e+00)\tAcc@1  88.00 ( 88.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.162 ( 0.162)\tLoss 1.5173e+00 (1.5173e+00)\tAcc@1  82.00 ( 82.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 82.000 Acc@5 0.000\n",
      "Epoch: [3][0/8]\tTime  0.125 ( 0.125)\tData  0.075 ( 0.075)\tLoss 8.4554e-01 (8.4554e-01)\tAcc@1  88.00 ( 88.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.128 ( 0.128)\tLoss 1.0764e+00 (1.0764e+00)\tAcc@1  82.00 ( 82.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 82.000 Acc@5 0.000\n",
      "Epoch: [4][0/8]\tTime  0.111 ( 0.111)\tData  0.056 ( 0.056)\tLoss 5.1945e-01 (5.1945e-01)\tAcc@1  90.00 ( 90.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.142 ( 0.142)\tLoss 2.9884e+00 (2.9884e+00)\tAcc@1  78.00 ( 78.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 83.000 Acc@5 0.000\n",
      "Epoch: [5][0/8]\tTime  0.102 ( 0.102)\tData  0.054 ( 0.054)\tLoss 8.8354e-01 (8.8354e-01)\tAcc@1  82.00 ( 82.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.128 ( 0.128)\tLoss 6.1476e-01 (6.1476e-01)\tAcc@1  90.00 ( 90.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 90.000 Acc@5 0.000\n",
      "Epoch: [6][0/8]\tTime  0.186 ( 0.186)\tData  0.100 ( 0.100)\tLoss 2.3297e-01 (2.3297e-01)\tAcc@1  92.00 ( 92.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.116 ( 0.116)\tLoss 1.0872e+00 (1.0872e+00)\tAcc@1  94.00 ( 94.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 95.000 Acc@5 0.000\n",
      "Epoch: [7][0/8]\tTime  0.147 ( 0.147)\tData  0.057 ( 0.057)\tLoss 5.9616e-01 (5.9616e-01)\tAcc@1  92.00 ( 92.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.125 ( 0.125)\tLoss 8.8134e-01 (8.8134e-01)\tAcc@1  90.00 ( 90.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 89.000 Acc@5 0.000\n",
      "Epoch: [8][0/8]\tTime  0.119 ( 0.119)\tData  0.058 ( 0.058)\tLoss 7.2216e-01 (7.2216e-01)\tAcc@1  88.00 ( 88.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.119 ( 0.119)\tLoss 9.7488e-01 (9.7488e-01)\tAcc@1  92.00 ( 92.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 95.000 Acc@5 0.000\n",
      "Epoch: [9][0/8]\tTime  0.120 ( 0.120)\tData  0.054 ( 0.054)\tLoss 2.1083e-01 (2.1083e-01)\tAcc@1  96.00 ( 96.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.127 ( 0.127)\tLoss 3.5149e-01 (3.5149e-01)\tAcc@1  90.00 ( 90.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 84.000 Acc@5 0.000\n",
      "Epoch: [10][0/8]\tTime  0.124 ( 0.124)\tData  0.053 ( 0.053)\tLoss 7.5499e-01 (7.5499e-01)\tAcc@1  80.00 ( 80.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.115 ( 0.115)\tLoss 1.0800e-01 (1.0800e-01)\tAcc@1  94.00 ( 94.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 93.000 Acc@5 0.000\n",
      "Epoch: [11][0/8]\tTime  0.127 ( 0.127)\tData  0.056 ( 0.056)\tLoss 7.3439e-02 (7.3439e-02)\tAcc@1  96.00 ( 96.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.122 ( 0.122)\tLoss 4.1847e-01 (4.1847e-01)\tAcc@1  94.00 ( 94.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 93.000 Acc@5 0.000\n",
      "Epoch: [12][0/8]\tTime  0.114 ( 0.114)\tData  0.052 ( 0.052)\tLoss 3.2126e-02 (3.2126e-02)\tAcc@1  98.00 ( 98.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.175 ( 0.175)\tLoss 2.4648e-01 (2.4648e-01)\tAcc@1  94.00 ( 94.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 96.000 Acc@5 0.000\n",
      "Epoch: [13][0/8]\tTime  0.154 ( 0.154)\tData  0.063 ( 0.063)\tLoss 7.2423e-02 (7.2423e-02)\tAcc@1  96.00 ( 96.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.115 ( 0.115)\tLoss 5.2884e-01 (5.2884e-01)\tAcc@1  94.00 ( 94.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 95.000 Acc@5 0.000\n",
      "Epoch: [14][0/8]\tTime  0.105 ( 0.105)\tData  0.050 ( 0.050)\tLoss 1.0824e-01 (1.0824e-01)\tAcc@1  98.00 ( 98.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.117 ( 0.117)\tLoss 2.2737e-01 (2.2737e-01)\tAcc@1  94.00 ( 94.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 94.000 Acc@5 0.000\n",
      "Epoch: [15][0/8]\tTime  0.126 ( 0.126)\tData  0.060 ( 0.060)\tLoss 1.5931e-01 (1.5931e-01)\tAcc@1  96.00 ( 96.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.128 ( 0.128)\tLoss 6.4709e-02 (6.4709e-02)\tAcc@1  94.00 ( 94.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 95.000 Acc@5 0.000\n",
      "Epoch: [16][0/8]\tTime  0.105 ( 0.105)\tData  0.057 ( 0.057)\tLoss 1.8482e-01 (1.8482e-01)\tAcc@1  90.00 ( 90.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.120 ( 0.120)\tLoss 4.1628e-01 (4.1628e-01)\tAcc@1  88.00 ( 88.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 94.000 Acc@5 0.000\n",
      "Epoch: [17][0/8]\tTime  0.101 ( 0.101)\tData  0.051 ( 0.051)\tLoss 2.1931e-01 (2.1931e-01)\tAcc@1  98.00 ( 98.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.122 ( 0.122)\tLoss 4.2293e-02 (4.2293e-02)\tAcc@1  98.00 ( 98.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 97.000 Acc@5 0.000\n",
      "Epoch: [18][0/8]\tTime  0.149 ( 0.149)\tData  0.057 ( 0.057)\tLoss 9.3902e-02 (9.3902e-02)\tAcc@1  96.00 ( 96.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.119 ( 0.119)\tLoss 9.2690e-02 (9.2690e-02)\tAcc@1  92.00 ( 92.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 93.000 Acc@5 0.000\n",
      "Epoch: [19][0/8]\tTime  0.344 ( 0.344)\tData  0.063 ( 0.063)\tLoss 1.1879e-01 (1.1879e-01)\tAcc@1  94.00 ( 94.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.205 ( 0.205)\tLoss 1.8565e-01 (1.8565e-01)\tAcc@1  96.00 ( 96.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 97.000 Acc@5 0.000\n",
      "Epoch: [20][0/8]\tTime  0.119 ( 0.119)\tData  0.052 ( 0.052)\tLoss 4.4604e-02 (4.4604e-02)\tAcc@1  96.00 ( 96.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.114 ( 0.114)\tLoss 1.2234e-01 (1.2234e-01)\tAcc@1  96.00 ( 96.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 98.000 Acc@5 0.000\n",
      "Epoch: [21][0/8]\tTime  0.199 ( 0.199)\tData  0.055 ( 0.055)\tLoss 1.6214e-01 (1.6214e-01)\tAcc@1  96.00 ( 96.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.123 ( 0.123)\tLoss 5.7178e-01 (5.7178e-01)\tAcc@1  90.00 ( 90.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 93.000 Acc@5 0.000\n",
      "Epoch: [22][0/8]\tTime  0.126 ( 0.126)\tData  0.056 ( 0.056)\tLoss 1.4114e-02 (1.4114e-02)\tAcc@1 100.00 (100.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.123 ( 0.123)\tLoss 3.8772e-01 (3.8772e-01)\tAcc@1  94.00 ( 94.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 95.000 Acc@5 0.000\n",
      "Epoch: [23][0/8]\tTime  0.115 ( 0.115)\tData  0.059 ( 0.059)\tLoss 5.1035e-02 (5.1035e-02)\tAcc@1  98.00 ( 98.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.138 ( 0.138)\tLoss 1.7815e-01 (1.7815e-01)\tAcc@1  96.00 ( 96.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 97.000 Acc@5 0.000\n",
      "Epoch: [24][0/8]\tTime  0.134 ( 0.134)\tData  0.082 ( 0.082)\tLoss 1.3219e-01 (1.3219e-01)\tAcc@1  94.00 ( 94.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/2]\tTime  0.112 ( 0.112)\tLoss 1.7716e-01 (1.7716e-01)\tAcc@1  96.00 ( 96.00)\tAcc@5   0.00 (  0.00)\n",
      " * Acc@1 96.000 Acc@5 0.000\n"
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "epochs = 25\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "   \n",
    "    adjust_learning_rate(optimizer, init_lr, epoch, epochs)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "    arch = 'vgg16'\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': arch,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "\n",
    "    if epoch == start_epoch:\n",
    "        sanity_check(model.state_dict(), pretrained)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
