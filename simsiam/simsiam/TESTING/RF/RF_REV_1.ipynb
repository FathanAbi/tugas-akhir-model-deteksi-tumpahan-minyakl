{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ab9c9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n",
      "GPU Name: NVIDIA GeForce RTX 4080 SUPER\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from HSI_class import HSI\n",
    "import zeroPadding\n",
    "import augmentation as aug\n",
    "import createSample as CS\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "\n",
    "# If available, print the GPU name\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "seeded_run = True\n",
    "seed = 2025\n",
    "\n",
    "sample_per_class = 5\n",
    "num_per_category_augment_1 = 10\n",
    "num_per_category_augment_2 = 10\n",
    "epochs = 200\n",
    "\n",
    "batch_size = 20\n",
    "test_size = 0.5\n",
    "\n",
    "random_indices = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91b478b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed has been set\n",
      "seet used: 2025\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # PyTorch determinism\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "if seeded_run:\n",
    "    set_seed(seed)\n",
    "    print(\"seed has been set\")\n",
    "    print(f\"seet used: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f79fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: D:\\FathanAbi\\tugas-akhir-model-deteksi-tumpahan-minyakl\\Hyperspectral oil spill detection datasets\\GM01.mat\n",
      "Processing file: D:\\FathanAbi\\tugas-akhir-model-deteksi-tumpahan-minyakl\\Hyperspectral oil spill detection datasets\\GM02.mat\n",
      "Processing file: D:\\FathanAbi\\tugas-akhir-model-deteksi-tumpahan-minyakl\\Hyperspectral oil spill detection datasets\\GM03.mat\n",
      "Processing file: D:\\FathanAbi\\tugas-akhir-model-deteksi-tumpahan-minyakl\\Hyperspectral oil spill detection datasets\\GM04.mat\n",
      "Processing file: D:\\FathanAbi\\tugas-akhir-model-deteksi-tumpahan-minyakl\\Hyperspectral oil spill detection datasets\\GM05.mat\n",
      "Processing file: D:\\FathanAbi\\tugas-akhir-model-deteksi-tumpahan-minyakl\\Hyperspectral oil spill detection datasets\\GM06.mat\n",
      "Processing file: D:\\FathanAbi\\tugas-akhir-model-deteksi-tumpahan-minyakl\\Hyperspectral oil spill detection datasets\\GM07.mat\n",
      "Processing file: D:\\FathanAbi\\tugas-akhir-model-deteksi-tumpahan-minyakl\\Hyperspectral oil spill detection datasets\\GM08.mat\n",
      "Processing file: D:\\FathanAbi\\tugas-akhir-model-deteksi-tumpahan-minyakl\\Hyperspectral oil spill detection datasets\\GM09.mat\n",
      "Processing file: D:\\FathanAbi\\tugas-akhir-model-deteksi-tumpahan-minyakl\\Hyperspectral oil spill detection datasets\\GM10.mat\n"
     ]
    }
   ],
   "source": [
    "dataset_path = r\"D:\\FathanAbi\\tugas-akhir-model-deteksi-tumpahan-minyakl\\Hyperspectral oil spill detection datasets\"\n",
    "\n",
    "datasets = []\n",
    "\n",
    "i = 0\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if i>9:\n",
    "        break\n",
    "    file_path = os.path.join(dataset_path, filename)\n",
    "    if os.path.isfile(file_path):  # Check if it's a file\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        hsi = HSI(file_path)\n",
    "        datasets.append(hsi)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31d40bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testWithDataset(n): \n",
    "    hsi_test = datasets[n]\n",
    "\n",
    "    test_img = hsi_test.img\n",
    "    test_gt = hsi_test.gt\n",
    "\n",
    "    patch_size = 9\n",
    "    half_patch = patch_size // 2\n",
    "\n",
    "    height = test_img.shape[0]\n",
    "    width = test_img.shape[1]\n",
    "\n",
    "    matrix=zeroPadding.zeroPadding_3D(test_img,half_patch) #add 0 in every side of the data\n",
    "    print(f\"img shape: {test_img.shape}\")\n",
    "    print(f\"img shape after padding {matrix.shape}\")\n",
    "    print(f\"number of pixel {width * height}\")\n",
    "\n",
    "    print(f\"ground truth shape: {test_gt.shape}\")\n",
    "\n",
    "    indices0 = np.argwhere(test_gt == 0)\n",
    "    indices1 = np.argwhere(test_gt == 1)\n",
    "\n",
    "    print(f\"indices = 0 shape: {indices0.shape}\")\n",
    "    print(f\"indices = 1 shape: {indices1.shape}\")\n",
    "\n",
    "    num_samples = 50\n",
    "\n",
    "    random_indices0 = indices0[np.random.choice(len(indices0), num_samples, replace=False)]\n",
    "    random_indices1 = indices1[np.random.choice(len(indices1), num_samples, replace=False)]\n",
    "\n",
    "    test_indices = np.vstack((random_indices0, random_indices1))\n",
    "\n",
    "    print(test_indices.shape)\n",
    "\n",
    "    return test_indices, test_gt, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e908e9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(model, batch_input, device):\n",
    "  test_features_np = torch.flatten(batch_input, start_dim=1)  # Flatten all dims except batch\n",
    "\n",
    "\n",
    "  # --- Predict class labels and probabilities ---\n",
    "  predicted_classes = model.predict(test_features_np)\n",
    "  probs = model.predict_proba(test_features_np)\n",
    "  positive_probs = probs[:, 1]  # probability of class 1\n",
    "\n",
    "  return predicted_classes, positive_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "532b0120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random: 0\n",
      "generating random sample\n",
      "hsi shape\n",
      "(1243, 684, 224)\n",
      "creating 5 Randomly chosen 0 indices:\n",
      "creating 5 Randomly chosen 1 indices:\n",
      "indices 0 used: [(np.int64(888), np.int64(614)), (np.int64(131), np.int64(311)), (np.int64(1028), np.int64(191)), (np.int64(765), np.int64(72)), (np.int64(282), np.int64(404))]\n",
      "indices 1 used: [(np.int64(510), np.int64(201)), (np.int64(1), np.int64(28)), (np.int64(299), np.int64(654)), (np.int64(304), np.int64(270)), (np.int64(551), np.int64(377))]\n",
      "number of element equal 0 5\n",
      "number of element equal 1 5\n",
      "x_train shape: (10, 9, 9, 224)\n",
      "y_train shape: (10,)\n"
     ]
    }
   ],
   "source": [
    "hsi_ = datasets[0]\n",
    "patch_size = 9\n",
    "\n",
    "\n",
    "indices_0 = []\n",
    "indices_1 = []\n",
    "\n",
    "print(f\"random: {random_indices}\")\n",
    "random_indices = 1\n",
    "if random_indices:\n",
    "    print(\"generating random sample\")\n",
    "    selected_patch_0, selected_patch_1, indices_0, indices_1 = CS.createSample(hsi_, patch_size, sample_per_class)\n",
    "else:\n",
    "    print(\"using generated indices\")\n",
    "    indices_0 = [(np.int64(188), np.int64(124)), (np.int64(523), np.int64(150)), (np.int64(1003), np.int64(474)), (np.int64(616), np.int64(508)), (np.int64(905), np.int64(552))]\n",
    "    indices_1 = [(np.int64(106), np.int64(606)), (np.int64(297), np.int64(468)), (np.int64(926), np.int64(35)), (np.int64(536), np.int64(519)), (np.int64(508), np.int64(442))]\n",
    "\n",
    "    selected_patch_0, selected_patch_1 = CS.getSample(hsi_, patch_size, sample_per_class, indices_0, indices_1)\n",
    "\n",
    "\n",
    "i =0\n",
    "half_patch = patch_size // 2\n",
    "\n",
    "\n",
    "indices = indices_0 +  indices_1\n",
    "\n",
    "# Concatenating along axis 0\n",
    "x_train = np.concatenate((selected_patch_0, selected_patch_1), )\n",
    "\n",
    "y_train = np.array([])\n",
    "\n",
    "gt = hsi_.gt\n",
    "for indice in indices:\n",
    "    # print(gt[indice[0]][indice[1]])\n",
    "    y_train = np.append(y_train, gt[indice[0]][indice[1]])\n",
    "\n",
    "count = np.count_nonzero(y_train == 0)  # Count elements equal to 0\n",
    "print(f'number of element equal 0 {count}')\n",
    "\n",
    "count = np.count_nonzero(y_train == 1)  # Count elements equal to 1\n",
    "print(f'number of element equal 1 {count}')\n",
    "\n",
    "\n",
    "\n",
    "# Print shape to verify\n",
    "print(f\"x_train shape: {x_train.shape}\")  # Expected output: (10, 9, 9, 224)\n",
    "print(f\"y_train shape: {y_train.shape}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15c89fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-225 -492  353  398  407  550  609  626  590  551  520  477  447  411\n",
      "  387  356  341  312  290  261  232  210  190  159  135  126  119  107\n",
      "  101   90   93   83   84   80   77   66   48   46   31    2   20   32\n",
      "   42    3   26   29   24   24   23    1    9   14   31   30   28   18\n",
      "   20    4  -11  -13   -8  -65 -175  -88  -10   -1   10   14   20   21\n",
      "   21   21   19   19   16   15   10    7   -5  -26 -174 -222 -127 -136\n",
      "  -48   -8   -2   -3    1   -7    6    3    9   11   10   14   10    0\n",
      "   11    8    2   -3   -8    4  -41  -74    0    0    0    0    0    0\n",
      "    0    0 -151 -343  -85  -59  -86  -68  -25   -8    2    3    5   10\n",
      "   13    3    3    8    8    9    4    8    6    6    1    7   14    7\n",
      "    5   11   10    9    0   -5    0    1   -3  -33  -64 -197    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  -40  -28  -26    0   -1  -17  -48  -15   -4    4    0    6    3    3\n",
      "    4    3    6    8    4    7    9    4    6    6   -1    4    0   16\n",
      "    4   -2    7    9   -3    7   -1   12    0    2    6    3   -7   -6\n",
      "    1   -4  -23  -17  -31    7  -22  -12   12   -2  -30  -32  -20  -23]\n",
      "[-225. -492.  353.  398.  407.  550.  609.  626.  590.  551.  520.  477.\n",
      "  447.  411.  387.  356.  341.  312.  290.  261.  232.  210.  190.  159.\n",
      "  135.  126.  119.  107.  101.   90.   93.   83.   84.   80.   77.   66.\n",
      "   48.   46.   31.    2.   20.   32.   42.    3.   26.   29.   24.   24.\n",
      "   23.    1.    9.   14.   31.   30.   28.   18.   20.    4.  -11.  -13.\n",
      "   -8.  -65. -175.  -88.  -10.   -1.   10.   14.   20.   21.   21.   21.\n",
      "   19.   19.   16.   15.   10.    7.   -5.  -26. -174. -222. -127. -136.\n",
      "  -48.   -8.   -2.   -3.    1.   -7.    6.    3.    9.   11.   10.   14.\n",
      "   10.    0.   11.    8.    2.   -3.   -8.    4.  -41.  -74.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0. -151. -343.  -85.  -59.  -86.  -68.\n",
      "  -25.   -8.    2.    3.    5.   10.   13.    3.    3.    8.    8.    9.\n",
      "    4.    8.    6.    6.    1.    7.   14.    7.    5.   11.   10.    9.\n",
      "    0.   -5.    0.    1.   -3.  -33.  -64. -197.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  -40.  -28.  -26.    0.   -1.  -17.  -48.  -15.   -4.    4.    0.    6.\n",
      "    3.    3.    4.    3.    6.    8.    4.    7.    9.    4.    6.    6.\n",
      "   -1.    4.    0.   16.    4.   -2.    7.    9.   -3.    7.   -1.   12.\n",
      "    0.    2.    6.    3.   -7.   -6.    1.   -4.  -23.  -17.  -31.    7.\n",
      "  -22.  -12.   12.   -2.  -30.  -32.  -20.  -23.]\n",
      "[-250 -517  309  395  410  520  607  619  623  597  572  521  483  447\n",
      "  420  393  381  362  347  328  312  295  284  268  255  241  233  224\n",
      "  221  214  210  205  202  197  186  171  161  155  150  134  140  149\n",
      "  158  138  151  157  149  144  149  136  140  146  156  152  152  149\n",
      "  143  119   98   89   87   16  -60   41  109  125  139  160  174  179\n",
      "  182  177  182  176  171  160  140  121   97   56 -174 -169  -51  -54\n",
      "   31   71   93  107  127  129  141  150  154  156  158  163  167  165\n",
      "  159  166  142  131  129   69   88   74    0    0    0    0    0    0\n",
      "    0    0 -207 -237  -35   22   25   27   68   85  106  119  129  139\n",
      "  149  149  159  162  163  162  160  162  160  162  158  152  150  152\n",
      "  150  158  143  137  129  117  108   94   87   62   62   56    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  -92  -28   33   17   31   55   53   66   68   83   85   99   96  114\n",
      "  105  114  118  119  126  122  119  123  123  127  129  115  127  134\n",
      "  121  125  112  123  121  120  115  109   95   82   81   78   83   65\n",
      "   72   39   27   47   39   75   36   19   12   22   -1  -32   32  -23]\n",
      "[-250. -517.  309.  395.  410.  520.  607.  619.  623.  597.  572.  521.\n",
      "  483.  447.  420.  393.  381.  362.  347.  328.  312.  295.  284.  268.\n",
      "  255.  241.  233.  224.  221.  214.  210.  205.  202.  197.  186.  171.\n",
      "  161.  155.  150.  134.  140.  149.  158.  138.  151.  157.  149.  144.\n",
      "  149.  136.  140.  146.  156.  152.  152.  149.  143.  119.   98.   89.\n",
      "   87.   16.  -60.   41.  109.  125.  139.  160.  174.  179.  182.  177.\n",
      "  182.  176.  171.  160.  140.  121.   97.   56. -174. -169.  -51.  -54.\n",
      "   31.   71.   93.  107.  127.  129.  141.  150.  154.  156.  158.  163.\n",
      "  167.  165.  159.  166.  142.  131.  129.   69.   88.   74.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0. -207. -237.  -35.   22.   25.   27.\n",
      "   68.   85.  106.  119.  129.  139.  149.  149.  159.  162.  163.  162.\n",
      "  160.  162.  160.  162.  158.  152.  150.  152.  150.  158.  143.  137.\n",
      "  129.  117.  108.   94.   87.   62.   62.   56.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  -92.  -28.   33.   17.   31.   55.   53.   66.   68.   83.   85.   99.\n",
      "   96.  114.  105.  114.  118.  119.  126.  122.  119.  123.  123.  127.\n",
      "  129.  115.  127.  134.  121.  125.  112.  123.  121.  120.  115.  109.\n",
      "   95.   82.   81.   78.   83.   65.   72.   39.   27.   47.   39.   75.\n",
      "   36.   19.   12.   22.   -1.  -32.   32.  -23.]\n",
      "[-215 -296  395  459  492  647  712  729  704  660  633  585  535  500\n",
      "  469  439  413  384  355  327  301  278  257  224  203  187  175  161\n",
      "  153  141  139  128  125  121  112   97   84   79   69   32   53   63\n",
      "   67   37   53   54   53   44   40   20   26   33   48   44   44   39\n",
      "   35   18    0   -7   -6  -62 -188  -82   -3    4   20   23   29   29\n",
      "   33   29   31   25   28   19   14   13    1  -31 -236 -277 -130 -126\n",
      "  -48  -11   -2    0    0    0    6    9   17   14   13   14   13   18\n",
      "   32   30    5    7    4 -118  -41  -54    0    0    0    0    0    0\n",
      "    0    0 -170  -92  -72  -50 -109  -46  -12    6   15   20   19   31\n",
      "   30   25   28   22   26   26   23   26   14   23   15   21   23   22\n",
      "   16   27   24   19   21   17   13    1    1   -9   -8  -12    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  -23  -42  -21    0   -8   -9  -22  -15    4   14   13   12   15    7\n",
      "    7   14   13   14   11   14   13   12   10   18   16   13   12   15\n",
      "   16    9   23   14   12   20   21    6   23    8    6    8   15    6\n",
      "    8  -12   -3  -17   -1  -24   13   18   -3  -12  -30  -11  -40    3]\n",
      "[-215. -296.  395.  459.  492.  647.  712.  729.  704.  660.  633.  585.\n",
      "  535.  500.  469.  439.  413.  384.  355.  327.  301.  278.  257.  224.\n",
      "  203.  187.  175.  161.  153.  141.  139.  128.  125.  121.  112.   97.\n",
      "   84.   79.   69.   32.   53.   63.   67.   37.   53.   54.   53.   44.\n",
      "   40.   20.   26.   33.   48.   44.   44.   39.   35.   18.    0.   -7.\n",
      "   -6.  -62. -188.  -82.   -3.    4.   20.   23.   29.   29.   33.   29.\n",
      "   31.   25.   28.   19.   14.   13.    1.  -31. -236. -277. -130. -126.\n",
      "  -48.  -11.   -2.    0.    0.    0.    6.    9.   17.   14.   13.   14.\n",
      "   13.   18.   32.   30.    5.    7.    4. -118.  -41.  -54.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0. -170.  -92.  -72.  -50. -109.  -46.\n",
      "  -12.    6.   15.   20.   19.   31.   30.   25.   28.   22.   26.   26.\n",
      "   23.   26.   14.   23.   15.   21.   23.   22.   16.   27.   24.   19.\n",
      "   21.   17.   13.    1.    1.   -9.   -8.  -12.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  -23.  -42.  -21.    0.   -8.   -9.  -22.  -15.    4.   14.   13.   12.\n",
      "   15.    7.    7.   14.   13.   14.   11.   14.   13.   12.   10.   18.\n",
      "   16.   13.   12.   15.   16.    9.   23.   14.   12.   20.   21.    6.\n",
      "   23.    8.    6.    8.   15.    6.    8.  -12.   -3.  -17.   -1.  -24.\n",
      "   13.   18.   -3.  -12.  -30.  -11.  -40.    3.]\n",
      "[-241 -422  358  385  415  535  616  617  595  556  525  476  442  407\n",
      "  380  362  354  333  313  289  272  250  242  233  222  206  197  194\n",
      "  196  202  202  202  201  194  188  176  166  158  162  146  151  156\n",
      "  159  148  160  162  163  164  167  169  164  170  182  183  184  181\n",
      "  177  164  142  132  129  167  119  182  182  193  202  224  246  256\n",
      "  266  265  265  263  267  252  223  193  175  148  158  157  169  157\n",
      "  126  139  168  184  219  226  246  248  259  268  282  310  303  290\n",
      "  289  246  213  205  218  195  256  247    0    0    0    0    0    0\n",
      "    0    0 -108  -22   31   22   45   65   97   94  109  115  122  108\n",
      "  146  148  150  165  171  170  172  180  176  170  168  156  157  162\n",
      "  162  170  173  147  150  115  110   98   96  100  116   54    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  -32  -23   24   35   38   58  130   96  102  106  128  158  167  154\n",
      "  147  162  162  157  180  174  170  184  200  173  185  180  178  176\n",
      "  165  156  151  149  136  126  120  102   83   85   73   65   69   45\n",
      "   49   46   67   32    8    6    6  -18  -15   25  -31  -10  -18  -21]\n",
      "[-241. -422.  358.  385.  415.  535.  616.  617.  595.  556.  525.  476.\n",
      "  442.  407.  380.  362.  354.  333.  313.  289.  272.  250.  242.  233.\n",
      "  222.  206.  197.  194.  196.  202.  202.  202.  201.  194.  188.  176.\n",
      "  166.  158.  162.  146.  151.  156.  159.  148.  160.  162.  163.  164.\n",
      "  167.  169.  164.  170.  182.  183.  184.  181.  177.  164.  142.  132.\n",
      "  129.  167.  119.  182.  182.  193.  202.  224.  246.  256.  266.  265.\n",
      "  265.  263.  267.  252.  223.  193.  175.  148.  158.  157.  169.  157.\n",
      "  126.  139.  168.  184.  219.  226.  246.  248.  259.  268.  282.  310.\n",
      "  303.  290.  289.  246.  213.  205.  218.  195.  256.  247.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0. -108.  -22.   31.   22.   45.   65.\n",
      "   97.   94.  109.  115.  122.  108.  146.  148.  150.  165.  171.  170.\n",
      "  172.  180.  176.  170.  168.  156.  157.  162.  162.  170.  173.  147.\n",
      "  150.  115.  110.   98.   96.  100.  116.   54.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  -32.  -23.   24.   35.   38.   58.  130.   96.  102.  106.  128.  158.\n",
      "  167.  154.  147.  162.  162.  157.  180.  174.  170.  184.  200.  173.\n",
      "  185.  180.  178.  176.  165.  156.  151.  149.  136.  126.  120.  102.\n",
      "   83.   85.   73.   65.   69.   45.   49.   46.   67.   32.    8.    6.\n",
      "    6.  -18.  -15.   25.  -31.  -10.  -18.  -21.]\n"
     ]
    }
   ],
   "source": [
    "i =1\n",
    "half_patch = patch_size // 2\n",
    "print(hsi_.img[indices_0[i][0]][indices_0[i][1]])\n",
    "print(selected_patch_0[i][half_patch][half_patch])\n",
    "\n",
    "print(hsi_.img[indices_1[i][0]][indices_1[i][1]])\n",
    "print(selected_patch_1[i][half_patch][half_patch])\n",
    "i =4\n",
    "half_patch = patch_size // 2\n",
    "print(hsi_.img[indices_0[i][0]][indices_0[i][1]])\n",
    "print(selected_patch_0[i][half_patch][half_patch])\n",
    "\n",
    "print(hsi_.img[indices_1[i][0]][indices_1[i][1]])\n",
    "print(selected_patch_1[i][half_patch][half_patch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd9ccef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hasil augmentasi 1 shape: (20, 9, 9, 224)\n",
      "label augmentai 1 shape: (20,)\n",
      "hasil augmentasi 2 shape: (20, 9, 9, 224)\n",
      "label augmentasi 2 shape: (20,)\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "hasil augmentasi gabungan untuk training: (40, 9, 9, 224)\n",
      "label augmentasi gabungan: (40,)\n",
      "Element 0 occurs 20 times.\n",
      "Element 1 occurs 20 times.\n"
     ]
    }
   ],
   "source": [
    "n_category = 2\n",
    "band_size = 224\n",
    "\n",
    "data_augment1, label_augment1 = aug.Augment_data(x_train, y_train, n_category, patch_size, band_size, num_per_category_augment_1)\n",
    "\n",
    "data_augment2, label_augment2 = aug.Augment_data2(x_train, y_train, n_category, patch_size, band_size, num_per_category_augment_2)\n",
    "\n",
    "print(f\"hasil augmentasi 1 shape: {data_augment1.shape}\")\n",
    "print(f\"label augmentai 1 shape: {label_augment1.shape}\")\n",
    "\n",
    "print(f\"hasil augmentasi 2 shape: {data_augment2.shape}\")\n",
    "print(f\"label augmentasi 2 shape: {label_augment2.shape}\")\n",
    "\n",
    "print(label_augment1)\n",
    "print(label_augment2)\n",
    "\n",
    "# # Count occurrences of each unique element\n",
    "# counts1 = np.bincount(label_augment1)\n",
    "\n",
    "# # Print results\n",
    "# for i, count in enumerate(counts1):\n",
    "#     print(f\"Element {i} occurs {count} times.\")\n",
    "\n",
    "# counts2 = np.bincount(label_augment2)\n",
    "\n",
    "# # Print results\n",
    "# for i, count in enumerate(counts2):\n",
    "#     print(f\"Element {i} occurs {count} times.\")\n",
    "\n",
    "# print(label_augment1[3])\n",
    "\n",
    "data_augment = np.concatenate((data_augment1, data_augment2))\n",
    "label_augment = np.concatenate((label_augment1, label_augment2))\n",
    "\n",
    "print(f\"hasil augmentasi gabungan untuk training: {data_augment.shape}\")\n",
    "print(f\"label augmentasi gabungan: {label_augment.shape}\")\n",
    "\n",
    "# print(label_augment)\n",
    "\n",
    "# Count occurrences of each unique element\n",
    "counts = np.bincount(label_augment)\n",
    "\n",
    "# Print results\n",
    "for i, count in enumerate(counts):\n",
    "    print(f\"Element {i} occurs {count} times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e55134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConvTo1D(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ConvTo1D, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels=224, out_channels=64, kernel_size=3, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "#         self.pool = nn.AdaptiveAvgPool2d((1, 1))  # (batch_size, 128, 1, 1)\n",
    "#         self.flatten = nn.Flatten()               # (batch_size, 128)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = self.pool(x)\n",
    "#         x = self.flatten(x)\n",
    "#         return x\n",
    "\n",
    "# feature_extractor = ConvTo1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59567562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 9, 9, 224)\n",
      "(40,)\n",
      "X_train shape: torch.Size([40, 224, 9, 9])\n",
      "torch.Size([40, 18144])\n"
     ]
    }
   ],
   "source": [
    "print(data_augment.shape)\n",
    "print(label_augment.shape)\n",
    "\n",
    "x_data = data_augment \n",
    "y_labels = label_augment\n",
    "\n",
    "x_data = torch.tensor(x_data)\n",
    "x_data = x_data.to(torch.float32)\n",
    "x_data = x_data.permute(0, 3, 1, 2)\n",
    "print(f\"X_train shape: {x_data.shape}\")\n",
    "\n",
    "features_np = torch.flatten(x_data, start_dim=1)  # Flatten all dims except batch\n",
    "\n",
    "    \n",
    "\n",
    "print(features_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e6cab40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 0 0 1 1 0 0 0 1 1 1 0 1 1 1 1]\n",
      "[0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "X = features_np\n",
    "y = y_labels\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "\n",
    "print(y_train)\n",
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b654b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0: Predicted = 0, Prob(class 1) = 0.1600\n",
      "Sample 1: Predicted = 0, Prob(class 1) = 0.0900\n",
      "Sample 2: Predicted = 1, Prob(class 1) = 0.9950\n",
      "Sample 3: Predicted = 0, Prob(class 1) = 0.0250\n",
      "Sample 4: Predicted = 1, Prob(class 1) = 0.9200\n",
      "Sample 5: Predicted = 1, Prob(class 1) = 0.9600\n",
      "Sample 6: Predicted = 0, Prob(class 1) = 0.1300\n",
      "Sample 7: Predicted = 0, Prob(class 1) = 0.0100\n",
      "Sample 8: Predicted = 1, Prob(class 1) = 0.8050\n",
      "Sample 9: Predicted = 0, Prob(class 1) = 0.1600\n",
      "Sample 10: Predicted = 1, Prob(class 1) = 0.8550\n",
      "Sample 11: Predicted = 1, Prob(class 1) = 0.9300\n",
      "Sample 12: Predicted = 0, Prob(class 1) = 0.1400\n",
      "Sample 13: Predicted = 1, Prob(class 1) = 0.9850\n",
      "Sample 14: Predicted = 0, Prob(class 1) = 0.1600\n",
      "Sample 15: Predicted = 0, Prob(class 1) = 0.0300\n",
      "Sample 16: Predicted = 0, Prob(class 1) = 0.1300\n",
      "Sample 17: Predicted = 1, Prob(class 1) = 0.8150\n",
      "Sample 18: Predicted = 0, Prob(class 1) = 0.0850\n",
      "Sample 19: Predicted = 1, Prob(class 1) = 0.9800\n",
      "Validation Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# --- Train Random Forest Classifier ---\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=20,\n",
    "        min_samples_leaf=2,\n",
    "        min_samples_split=2,\n",
    "        random_state=seed\n",
    "    )\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# --- Predict class labels and probabilities ---\n",
    "predicted_classes = pipeline.predict(X_val)\n",
    "probs = pipeline.predict_proba(X_val)\n",
    "positive_probs = probs[:, 1]  # probability of class 1\n",
    "\n",
    "# --- Display predictions with probabilities ---\n",
    "for i, (pred, prob) in enumerate(zip(predicted_classes, positive_probs)):\n",
    "    print(f\"Sample {i}: Predicted = {pred}, Prob(class 1) = {prob:.4f}\")\n",
    "\n",
    "# --- Accuracy ---\n",
    "acc = accuracy_score(y_val, predicted_classes)\n",
    "print(f\"Validation Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36c8a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testWithWholeDataset(n): \n",
    "    hsi_test = datasets[n]\n",
    "\n",
    "    test_img = hsi_test.img\n",
    "    gt= hsi_test.gt\n",
    "\n",
    "    patch_size = 9\n",
    "    half_patch = patch_size // 2\n",
    "\n",
    "    height = test_img.shape[0]\n",
    "    width = test_img.shape[1]\n",
    "\n",
    "    matrix=zeroPadding.zeroPadding_3D(test_img,half_patch) #add 0 in every side of the data\n",
    "    print(f\"img shape: {test_img.shape}\")\n",
    "    print(f\"img shape after padding {matrix.shape}\")\n",
    "    print(f\"number of pixel {width * height}\")\n",
    "\n",
    "    print(f\"ground truth shape: {gt.shape}\")\n",
    "\n",
    "    indices0 = np.argwhere(gt == 0)\n",
    "    indices1 = np.argwhere(gt == 1)\n",
    "\n",
    "    print(f\"indices = 0 shape: {indices0.shape}\")\n",
    "    print(f\"indices = 1 shape: {indices1.shape}\")\n",
    "\n",
    "    return matrix, gt, indices0.shape, indices1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72dbb855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch_whole(model, batch_input, device):\n",
    "  test_features_np = torch.flatten(batch_input, start_dim=1)  # Flatten all dims except batch\n",
    "  # convert to NumPy\n",
    "\n",
    "# --- Predict class labels and probabilities ---\n",
    "  predicted_classes = model.predict(test_features_np)\n",
    "  probs = model.predict_proba(test_features_np)\n",
    "  positive_probs = probs[:, 1]  # probability of class 1\n",
    "\n",
    "  return predicted_classes, positive_probs\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "288947cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, matrix, gt, half_patch, expected_shape):\n",
    "        self.matrix = matrix\n",
    "        self.gt = gt\n",
    "        self.half_patch = half_patch\n",
    "        self.expected_shape = expected_shape\n",
    "        self.size_x, self.size_y = matrix.shape[0], matrix.shape[1]\n",
    "        self.valid_coords = [\n",
    "            (x, y)\n",
    "            for x in range(half_patch, self.size_x - half_patch)\n",
    "            for y in range(half_patch, self.size_y - half_patch)\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_coords)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.valid_coords[idx]\n",
    "        true_label = self.gt[x - self.half_patch, y - self.half_patch]\n",
    "\n",
    "        selected_rows = self.matrix[x- self.half_patch:x + 2 * self.half_patch + 1 - self.half_patch, :]\n",
    "        testing_patch = selected_rows[:, y - self.half_patch:y + 2 * self.half_patch + 1 - self.half_patch]\n",
    "\n",
    "        # Verify patch size\n",
    "        if testing_patch.shape != self.expected_shape:\n",
    "            raise ValueError(f\"Patch at ({x},{y}) has wrong shape {testing_patch.shape}\")\n",
    "\n",
    "        patch_tensor = torch.tensor(testing_patch, dtype=torch.float32)\n",
    "        patch_tensor = patch_tensor.permute(2, 0, 1)  # (C, H, W)\n",
    "\n",
    "        return patch_tensor, true_label, x, y  # Also return (x, y) for positioning later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fd9eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScore(prediction, y_probs, groundtruth):\n",
    "    groundtruths = groundtruth\n",
    "    groundtruth_in = []\n",
    "\n",
    "    for x in groundtruths:\n",
    "        groundtruth_in.append(x)\n",
    "\n",
    "    predictions = prediction\n",
    "    prediction_in = []\n",
    "\n",
    "    for x in predictions:\n",
    "        for y in x:\n",
    "            prediction_in.append(y)\n",
    "\n",
    "\n",
    "    y_prob_in = []\n",
    "\n",
    "    for x in y_probs:\n",
    "        for y in x:\n",
    "            y_prob_in.append(y)\n",
    "\n",
    "    # print(len(groundtruth_in))\n",
    "    # print(len(prediction_in))\n",
    "    # print(len(y_prob_in))\n",
    "\n",
    "    y_test = groundtruth_in\n",
    "    y_pred = prediction_in\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in zip(y_test, y_pred):\n",
    "        total += 1\n",
    "        if x == y:\n",
    "            correct += 1\n",
    "    \n",
    "    print(f'{correct}/{total}')\n",
    "\n",
    "    y_test_np = np.array([label.item() for label in y_test])\n",
    "    # Ensure labels are binary (0 and 1)\n",
    "    # print(\"Unique values in y_test:\", pd.Series(y_test_np).unique())\n",
    "\n",
    "    # # Check if y_pred is probability (float) or hard prediction (int)\n",
    "    # print(\"Sample y_pred values:\", y_pred[:5])\n",
    "\n",
    "    test_df = pd.DataFrame(\n",
    "        {'True': y_test_np, 'Model': y_prob_in})\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(test_df['True'], test_df['Model'])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'Model (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Random Guess')\n",
    "\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves for Two Models')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    y_true = np.array([int(label) for label in y_test_np])  # true labels\n",
    "    y_pred = prediction_in                         # predicted class labels (e.g., from predict_batch)\n",
    "\n",
    "    # Precision, Recall, F1\n",
    "    precision = precision_score(y_true, y_pred, average='macro')  # Use 'binary' if binary task\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Overall Accuracy (OA)\n",
    "    oa = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Average Accuracy (AA) — mean of per-class accuracies\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "    aa = per_class_acc.mean()\n",
    "\n",
    "    # Print all metrics\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"OA:        {oa:.4f}\")\n",
    "    print(f\"AA:        {aa:.4f}\")\n",
    "\n",
    "    performance = {\n",
    "        'AUC': float(roc_auc),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'F1 Score': float(f1),\n",
    "        'OA': float(oa),\n",
    "        'AA': float(aa),\n",
    "    }\n",
    "\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c17b635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape: (1243, 684, 224)\n",
      "img shape after padding (1251, 692, 224)\n",
      "number of pixel 850212\n",
      "ground truth shape: (1243, 684)\n",
      "indices = 0 shape: (820876, 2)\n",
      "indices = 1 shape: (29336, 2)\n",
      "820876\n",
      "29336\n",
      "generate data loader using seed\n",
      "torch.Size([64, 224, 9, 9])\n",
      "torch.Size([64])\n",
      "data loader size: 13285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 13285/13285 [05:28<00:00, 40.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct0 = 720203\n",
      "correct1 = 24046\n",
      "Score: 744249/850212\n",
      "{'dataset': 0, 'class0_size': 820876, 'class1_size': 29336, 'correct_0': 720203, 'correct_1': 24046, 'correct_total': 744249, 'total': 850212}\n",
      "img shape: (1786, 699, 224)\n",
      "img shape after padding (1794, 707, 224)\n",
      "number of pixel 1248414\n",
      "ground truth shape: (1786, 699)\n",
      "indices = 0 shape: (1236269, 2)\n",
      "indices = 1 shape: (12145, 2)\n",
      "1236269\n",
      "12145\n",
      "generate data loader using seed\n",
      "torch.Size([64, 224, 9, 9])\n",
      "torch.Size([64])\n",
      "data loader size: 19507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 19507/19507 [08:20<00:00, 38.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct0 = 262053\n",
      "correct1 = 12114\n",
      "Score: 274167/1248414\n",
      "{'dataset': 1, 'class0_size': 1236269, 'class1_size': 12145, 'correct_0': 262053, 'correct_1': 12114, 'correct_total': 274167, 'total': 1248414}\n",
      "img shape: (1386, 690, 224)\n",
      "img shape after padding (1394, 698, 224)\n",
      "number of pixel 956340\n",
      "ground truth shape: (1386, 690)\n",
      "indices = 0 shape: (916980, 2)\n",
      "indices = 1 shape: (39360, 2)\n",
      "916980\n",
      "39360\n",
      "generate data loader using seed\n",
      "torch.Size([64, 224, 9, 9])\n",
      "torch.Size([64])\n",
      "data loader size: 14943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 14943/14943 [06:22<00:00, 39.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct0 = 630852\n",
      "correct1 = 39339\n",
      "Score: 670191/956340\n",
      "{'dataset': 2, 'class0_size': 916980, 'class1_size': 39360, 'correct_0': 630852, 'correct_1': 39339, 'correct_total': 670191, 'total': 956340}\n",
      "img shape: (1466, 676, 224)\n",
      "img shape after padding (1474, 684, 224)\n",
      "number of pixel 991016\n",
      "ground truth shape: (1466, 676)\n",
      "indices = 0 shape: (959167, 2)\n",
      "indices = 1 shape: (31849, 2)\n",
      "959167\n",
      "31849\n",
      "generate data loader using seed\n",
      "torch.Size([64, 224, 9, 9])\n",
      "torch.Size([64])\n",
      "data loader size: 15485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 15485/15485 [06:23<00:00, 40.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct0 = 802840\n",
      "correct1 = 31819\n",
      "Score: 834659/991016\n",
      "{'dataset': 3, 'class0_size': 959167, 'class1_size': 31849, 'correct_0': 802840, 'correct_1': 31819, 'correct_total': 834659, 'total': 991016}\n",
      "img shape: (2085, 682, 224)\n",
      "img shape after padding (2093, 690, 224)\n",
      "number of pixel 1421970\n",
      "ground truth shape: (2085, 682)\n",
      "indices = 0 shape: (1363408, 2)\n",
      "indices = 1 shape: (58562, 2)\n",
      "1363408\n",
      "58562\n",
      "generate data loader using seed\n",
      "torch.Size([64, 224, 9, 9])\n",
      "torch.Size([64])\n",
      "data loader size: 22219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 22219/22219 [08:20<00:00, 44.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct0 = 919646\n",
      "correct1 = 58176\n",
      "Score: 977822/1421970\n",
      "{'dataset': 4, 'class0_size': 1363408, 'class1_size': 58562, 'correct_0': 919646, 'correct_1': 58176, 'correct_total': 977822, 'total': 1421970}\n",
      "img shape: (2088, 691, 224)\n",
      "img shape after padding (2096, 699, 224)\n",
      "number of pixel 1442808\n",
      "ground truth shape: (2088, 691)\n",
      "indices = 0 shape: (1389552, 2)\n",
      "indices = 1 shape: (53256, 2)\n",
      "1389552\n",
      "53256\n",
      "generate data loader using seed\n",
      "torch.Size([64, 224, 9, 9])\n",
      "torch.Size([64])\n",
      "data loader size: 22544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 22544/22544 [08:24<00:00, 44.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct0 = 1179805\n",
      "correct1 = 52811\n",
      "Score: 1232616/1442808\n",
      "{'dataset': 5, 'class0_size': 1389552, 'class1_size': 53256, 'correct_0': 1179805, 'correct_1': 52811, 'correct_total': 1232616, 'total': 1442808}\n",
      "img shape: (1965, 492, 224)\n",
      "img shape after padding (1973, 500, 224)\n",
      "number of pixel 966780\n",
      "ground truth shape: (1965, 492)\n",
      "indices = 0 shape: (873365, 2)\n",
      "indices = 1 shape: (93415, 2)\n",
      "873365\n",
      "93415\n",
      "generate data loader using seed\n",
      "torch.Size([64, 224, 9, 9])\n",
      "torch.Size([64])\n",
      "data loader size: 15106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  28%|██▊       | 4186/15106 [01:33<04:15, 42.79it/s]"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "scores = []\n",
    "groundtruth = []\n",
    "prediction = []\n",
    "y_probs = []\n",
    "\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "os.makedirs(f\"predictions/{timestamp}\", exist_ok=True)\n",
    "for dataset in range(len(datasets)):\n",
    "    if dataset > 2:\n",
    "        break\n",
    "    print(f\"dataset: {dataset + 1}\")\n",
    "    hsi_prediction = []\n",
    "    hsi_yprobs = []\n",
    "    hsi_groundtruth = []\n",
    "\n",
    "    score = []\n",
    "    patch_size = 9\n",
    "    half_patch = patch_size // 2\n",
    "\n",
    "    data_sampler = None\n",
    "    batch_size = 64\n",
    "\n",
    "    correct0 = 0\n",
    "    correct1 = 0\n",
    "    matrix = []\n",
    "    gt = []\n",
    "    expected_patch_shape = []\n",
    "    dataset_patches = []\n",
    "    data_loader = []\n",
    "    patch_tensor = []\n",
    "    true_label = [] \n",
    "    x = []\n",
    "    y = []\n",
    "    pred_matrix = []\n",
    "\n",
    "    matrix, gt, indices_0_shape, indices_1_shape = testWithWholeDataset(dataset)\n",
    "    print(indices_0_shape[0])\n",
    "    print(indices_1_shape[0])\n",
    "\n",
    "    expected_patch_shape = (2 * half_patch + 1, 2 * half_patch + 1, matrix.shape[2])\n",
    "    dataset_patches = PatchDataset(matrix, gt, half_patch, expected_patch_shape)\n",
    "\n",
    "    if seeded_run:\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(seed)\n",
    "\n",
    "        data_loader = DataLoader(\n",
    "            dataset_patches,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,  # set to True if needed\n",
    "            num_workers=0,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "            generator=g\n",
    "        )\n",
    "        print(\"generate data loader using seed\")\n",
    "    else:\n",
    "        data_loader = DataLoader(dataset_patches, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    patch_tensor, true_label, x, y = next(iter(data_loader))\n",
    "\n",
    "    print(patch_tensor.size())\n",
    "    print(true_label.size())\n",
    "    print(f\"data loader size: {len(data_loader)}\")\n",
    "\n",
    "    pred_matrix = np.full(gt.shape, -1, dtype=np.int32)\n",
    "    correct = 0\n",
    "\n",
    "    for input_batch, label_batch, x_batch, y_batch in tqdm(data_loader, desc=\"Predicting\"):\n",
    "\n",
    "\n",
    "        preds, confs = predict_batch_whole(pipeline, input_batch, device)\n",
    "\n",
    "        hsi_prediction.append(preds)\n",
    "        prediction.append(preds)\n",
    "        hsi_yprobs.append(confs)\n",
    "        y_probs.append(confs)\n",
    "        \n",
    "        label_batch = label_batch.numpy()\n",
    "        x_batch = x_batch.numpy()\n",
    "        y_batch = y_batch.numpy()\n",
    "\n",
    "        for pred, label, x, y in zip(preds, label_batch, x_batch, y_batch):\n",
    "            hsi_groundtruth.append(label)\n",
    "            groundtruth.append(label)\n",
    "            pred_matrix[x - half_patch, y - half_patch] = pred\n",
    "            if pred == label:\n",
    "                if label == 0:\n",
    "                    correct0 += 1\n",
    "                elif label == 1:\n",
    "                    correct1 += 1\n",
    "\n",
    "    performance_metrics = getScore(hsi_prediction, hsi_yprobs, hsi_groundtruth)      \n",
    "          \n",
    "    correct = correct0+correct1\n",
    "    print(f\"correct0 = {correct0}\")\n",
    "    print(f\"correct1 = {correct1}\")\n",
    "    total = gt.shape[0] * gt.shape[1]\n",
    "    print(f\"Score: {correct}/{total}\")\n",
    "\n",
    "    score = {\n",
    "        'dataset': dataset,\n",
    "        'class0_size': indices_0_shape[0],\n",
    "        'class1_size': indices_1_shape[0],\n",
    "        'correct_0': correct0,\n",
    "        'correct_1': correct1,\n",
    "        'correct_total': correct,\n",
    "        'total': total,\n",
    "        'AUC': float(performance_metrics['AUC']),\n",
    "        'precision': float(performance_metrics['precision']),\n",
    "        'recall': float(performance_metrics['recall']),\n",
    "        'F1 Score': float(performance_metrics['F1 Score']),\n",
    "        'OA': float(performance_metrics['OA']),\n",
    "        'AA': float(performance_metrics['AA']),\n",
    "    }\n",
    "    # print(score)\n",
    "    scores.append(score)\n",
    "    # Save prediction matrix\n",
    "    # timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    np.save(f\"predictions/{timestamp}/results {dataset} RF.npy\", pred_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f93559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_correct = 0\n",
    "all_total = 0\n",
    "all_correct0 = 0\n",
    "all_correct1 = 0\n",
    "class0_total = 0\n",
    "class1_total = 0\n",
    "\n",
    "for score in scores:\n",
    "    dataset = score['dataset']\n",
    "    correct0 = score['correct_0']\n",
    "    correct1 = score['correct_1']\n",
    "    class0_size = score['class0_size']\n",
    "    class1_size = score['class1_size']\n",
    "    correct = score['correct_total']\n",
    "    total = score['total']\n",
    "    print(f\"dataset: {dataset}\\t\", f'{correct0}/{class0_size}\\t', f'{correct1}/{class1_size}\\t', f'{correct}/{total}\\t')\n",
    "\n",
    "    all_correct += correct\n",
    "    all_total += total\n",
    "    all_correct0 += correct0\n",
    "    all_correct1 += correct1\n",
    "    class0_total += class0_size\n",
    "    class1_total += class1_size\n",
    "\n",
    "\n",
    "\n",
    "print(f\"total: \\t\\t {all_correct0}/{class0_total/2} \\t {all_correct1}/{class1_total/2} \\t {all_correct}/{all_total}\")\n",
    "\n",
    "print(f\"acc: {all_correct/all_total}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823b46ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_total_score = {\n",
    "    'dataset': 'Total Dataset',\n",
    "    'correct_0': all_correct0,\n",
    "    'correct_1': all_correct1,\n",
    "    'class0_total': class0_total,\n",
    "    'class1_total': class1_total,\n",
    "    'correct_total': all_correct,\n",
    "    'total': all_total\n",
    "}\n",
    "\n",
    "scores.append(all_total_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee05689",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruths = groundtruth\n",
    "groundtruth_in = []\n",
    "\n",
    "for x in groundtruths:\n",
    "    groundtruth_in.append(x)\n",
    "\n",
    "predictions = prediction\n",
    "prediction_in = []\n",
    "\n",
    "for x in predictions:\n",
    "    for y in x:\n",
    "        prediction_in.append(y)\n",
    "\n",
    "\n",
    "y_prob_in = []\n",
    "\n",
    "for x in y_probs:\n",
    "    for y in x:\n",
    "        y_prob_in.append(y)\n",
    "\n",
    "print(len(groundtruth_in))\n",
    "print(len(prediction_in))\n",
    "print(len(y_prob_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e42082",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = groundtruth_in\n",
    "y_pred = prediction_in\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for x, y in zip(y_test, y_pred):\n",
    "    total += 1\n",
    "    if x == y:\n",
    "        correct += 1\n",
    "\n",
    "print(f'{correct}/{total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b0e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_np = np.array([label.item() for label in y_test])\n",
    "# Ensure labels are binary (0 and 1)\n",
    "print(\"Unique values in y_test:\", pd.Series(y_test_np).unique())\n",
    "\n",
    "# Check if y_pred is probability (float) or hard prediction (int)\n",
    "print(\"Sample y_pred values:\", y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e48bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_df = pd.DataFrame(\n",
    "    {'True': y_test_np, 'Model': y_prob_in})\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "\n",
    "fpr, tpr, _ = roc_curve(test_df['True'], test_df['Model'])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label=f'Model (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'r--', label='Random Guess')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Two Models')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6750deae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_true = np.array([int(label) for label in y_test_np])  # true labels\n",
    "y_pred = prediction_in                         # predicted class labels (e.g., from predict_batch)\n",
    "\n",
    "# Precision, Recall, F1\n",
    "precision = precision_score(y_true, y_pred, average='macro')  # Use 'binary' if binary task\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "# Overall Accuracy (OA)\n",
    "oa = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Average Accuracy (AA) — mean of per-class accuracies\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "aa = per_class_acc.mean()\n",
    "\n",
    "# Print all metrics\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"OA:        {oa:.4f}\")\n",
    "print(f\"AA:        {aa:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63022330",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = {\n",
    "    'AUC': float(roc_auc),\n",
    "    'precision': float(precision),\n",
    "    'recall': float(recall),\n",
    "    'F1 Score': float(f1),\n",
    "    'OA': float(oa),\n",
    "    'AA': float(aa),\n",
    "}\n",
    "result_json = {\n",
    "    'prediction' : scores,\n",
    "    'performance' : performance,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711abcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "print(result_json)\n",
    "\n",
    "with open(f\"performance/RF {timestamp}_results.json\", \"w\") as f:\n",
    "    json.dump(result_json, f, indent=2)\n",
    "\n",
    "print(\"JSON saved to results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bcd9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "print(f\"Run time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "print(timestamp)\n",
    "print(f\"seet used: {seed}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fathanvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
