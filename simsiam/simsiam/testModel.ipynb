{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ab9c9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg16\n",
    "from HSI_class import HSI\n",
    "\n",
    "import zeroPadding\n",
    "\n",
    "\n",
    "model_path = r\"C:\\Users\\Asus TUF\\Documents\\code\\TA\\simsiam\\simsiam\\models\\finetune\\20250501_194137_checkpoint_0010.pth.tar\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6f79fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM01.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM02.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM03.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM04.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM05.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM06.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM07.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM08.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM09.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM10.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM11.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM12.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM13.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM14.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM15.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM16.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM17.mat\n",
      "Processing file: C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\\GM18.mat\n"
     ]
    }
   ],
   "source": [
    "dataset_path = r\"C:\\Users\\Asus TUF\\Documents\\code\\TA\\Hyperspectral oil spill detection datasets\"\n",
    "\n",
    "datasets = []\n",
    "\n",
    "i = 0\n",
    "for filename in os.listdir(dataset_path):\n",
    "    # if i>0:\n",
    "    #     break\n",
    "    file_path = os.path.join(dataset_path, filename)\n",
    "    if os.path.isfile(file_path):  # Check if it's a file\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        hsi = HSI(file_path)\n",
    "        datasets.append(hsi)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31d40bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testWithDataset(n): \n",
    "    hsi_test = datasets[n]\n",
    "\n",
    "    test_img = hsi_test.img\n",
    "    test_gt = hsi_test.gt\n",
    "\n",
    "    patch_size = 9\n",
    "    half_patch = patch_size // 2\n",
    "\n",
    "    height = test_img.shape[0]\n",
    "    width = test_img.shape[1]\n",
    "\n",
    "    matrix=zeroPadding.zeroPadding_3D(test_img,half_patch) #add 0 in every side of the data\n",
    "    print(f\"img shape: {test_img.shape}\")\n",
    "    print(f\"img shape after padding {matrix.shape}\")\n",
    "    print(f\"number of pixel {width * height}\")\n",
    "\n",
    "    print(f\"ground truth shape: {test_gt.shape}\")\n",
    "\n",
    "    indices0 = np.argwhere(test_gt == 0)\n",
    "    indices1 = np.argwhere(test_gt == 1)\n",
    "\n",
    "    print(f\"indices = 0 shape: {indices0.shape}\")\n",
    "    print(f\"indices = 1 shape: {indices1.shape}\")\n",
    "\n",
    "    num_samples = 1000\n",
    "\n",
    "    random_indices0 = indices0[np.random.choice(len(indices0), num_samples, replace=False)]\n",
    "    random_indices1 = indices1[np.random.choice(len(indices1), num_samples, replace=False)]\n",
    "\n",
    "    test_indices = np.vstack((random_indices0, random_indices1))\n",
    "\n",
    "    print(test_indices.shape)\n",
    "\n",
    "    return test_indices, test_gt, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af1b2bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16_HSI(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(VGG16_HSI, self).__init__()\n",
    "\n",
    "         # Custom Convolutional Layer: Process 9x9x224 input\n",
    "        self.pre_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=224, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))  # Reduce to (256, 1, 1)\n",
    "        )\n",
    "\n",
    "        # Fully Connected Layer to reshape to (64, 56, 56)\n",
    "        self.fc = nn.Linear(256 * 1 * 1, 64 * 56 * 56)\n",
    "\n",
    "        # Load VGG-16 Model\n",
    "        self.encoder = vgg16(pretrained=False)\n",
    "\n",
    "        # Remove first VGG-16 conv layer\n",
    "        self.encoder.features = nn.Sequential(*list(self.encoder.features.children())[1:])\n",
    "\n",
    "        # Modify classifier to output 2 classes\n",
    "        self.encoder.classifier[6] = nn.Linear(4096, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(f'before {x.shape}')\n",
    "        x = self.pre_conv(x)  # Process hyperspectral input\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "\n",
    "        # print(f'after preconv {x.shape}')\n",
    "        x = self.fc(x)  # Fully connected layer\n",
    "        # print(f'after fc {x.shape}')\n",
    "        # Reshape to (batch_size, 64, 56, 56) before passing to VGG\n",
    "        x = x.view(x.size(0), 64, 56, 56)\n",
    "        # print(f'after reshape, before vgg second layer {x.shape}')\n",
    "\n",
    "        x = self.encoder.features(x)  # Pass to VGG-16\n",
    "        x = self.encoder.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.encoder.classifier(x)  # Final classification layer\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e908e9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(model, batch_input, device):\n",
    "    model.eval()\n",
    "    batch_input = batch_input.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_input)\n",
    "\n",
    "    predicted_classes = torch.argmax(output, dim=1).cpu().numpy()\n",
    "    confidences = torch.nn.functional.softmax(output, dim=1)\n",
    "    confidences = confidences[range(len(predicted_classes)), predicted_classes].cpu().numpy()\n",
    "\n",
    "    return predicted_classes, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e707b287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model 20250501_194137_checkpoint_0010.pth.tar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus TUF\\Documents\\code\\TA\\myenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus TUF\\Documents\\code\\TA\\myenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Asus TUF\\AppData\\Local\\Temp\\ipykernel_12708\\2876424645.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and moved to device\n",
      "tes: 0\n",
      "img shape: (1243, 684, 224)\n",
      "img shape after padding (1251, 692, 224)\n",
      "number of pixel 850212\n",
      "ground truth shape: (1243, 684)\n",
      "indices = 0 shape: (820876, 2)\n",
      "indices = 1 shape: (29336, 2)\n",
      "(2000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 32/32 [00:27<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 997/2000\n",
      "tes: 1\n",
      "img shape: (1786, 699, 224)\n",
      "img shape after padding (1794, 707, 224)\n",
      "number of pixel 1248414\n",
      "ground truth shape: (1786, 699)\n",
      "indices = 0 shape: (1236269, 2)\n",
      "indices = 1 shape: (12145, 2)\n",
      "(2000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 32/32 [00:24<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1017/2000\n",
      "tes: 2\n",
      "img shape: (1386, 690, 224)\n",
      "img shape after padding (1394, 698, 224)\n",
      "number of pixel 956340\n",
      "ground truth shape: (1386, 690)\n",
      "indices = 0 shape: (916980, 2)\n",
      "indices = 1 shape: (39360, 2)\n",
      "(2000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 32/32 [00:23<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1248/2000\n",
      "tes: 3\n",
      "img shape: (1466, 676, 224)\n",
      "img shape after padding (1474, 684, 224)\n",
      "number of pixel 991016\n",
      "ground truth shape: (1466, 676)\n",
      "indices = 0 shape: (959167, 2)\n",
      "indices = 1 shape: (31849, 2)\n",
      "(2000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 32/32 [00:23<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1016/2000\n",
      "tes: 4\n",
      "img shape: (2085, 682, 224)\n",
      "img shape after padding (2093, 690, 224)\n",
      "number of pixel 1421970\n",
      "ground truth shape: (2085, 682)\n",
      "indices = 0 shape: (1363408, 2)\n",
      "indices = 1 shape: (58562, 2)\n",
      "(2000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 32/32 [00:24<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1414/2000\n",
      "tes: 5\n",
      "img shape: (2088, 691, 224)\n",
      "img shape after padding (2096, 699, 224)\n",
      "number of pixel 1442808\n",
      "ground truth shape: (2088, 691)\n",
      "indices = 0 shape: (1389552, 2)\n",
      "indices = 1 shape: (53256, 2)\n",
      "(2000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 32/32 [00:24<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1028/2000\n",
      "tes: 6\n",
      "img shape: (1965, 492, 224)\n",
      "img shape after padding (1973, 500, 224)\n",
      "number of pixel 966780\n",
      "ground truth shape: (1965, 492)\n",
      "indices = 0 shape: (873365, 2)\n",
      "indices = 1 shape: (93415, 2)\n",
      "(2000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 32/32 [00:23<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1000/2000\n",
      "tes: 7\n",
      "img shape: (1532, 567, 224)\n",
      "img shape after padding (1540, 575, 224)\n",
      "number of pixel 868644\n",
      "ground truth shape: (1532, 567)\n",
      "indices = 0 shape: (824964, 2)\n",
      "indices = 1 shape: (43680, 2)\n",
      "(2000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 32/32 [00:23<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1000/2000\n",
      "tes: 8\n",
      "img shape: (1569, 517, 224)\n",
      "img shape after padding (1577, 525, 224)\n",
      "number of pixel 811173\n",
      "ground truth shape: (1569, 517)\n",
      "indices = 0 shape: (742935, 2)\n",
      "indices = 1 shape: (68238, 2)\n",
      "(2000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 32/32 [00:24<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1000/2000\n",
      "tes: 9\n",
      "img shape: (1084, 680, 224)\n",
      "img shape after padding (1092, 688, 224)\n",
      "number of pixel 737120\n",
      "ground truth shape: (1084, 680)\n",
      "indices = 0 shape: (691437, 2)\n",
      "indices = 1 shape: (45683, 2)\n",
      "(2000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 32/32 [00:24<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1000/2000\n",
      "tes: 10\n",
      "img shape: (1185, 682, 224)\n",
      "img shape after padding (1193, 690, 224)\n",
      "number of pixel 808170\n",
      "ground truth shape: (1185, 682)\n",
      "indices = 0 shape: (770065, 2)\n",
      "indices = 1 shape: (38105, 2)\n",
      "(2000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 32/32 [00:24<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1000/2000\n",
      "tes: 11\n",
      "img shape: (842, 640, 224)\n",
      "img shape after padding (850, 648, 224)\n",
      "number of pixel 538880\n",
      "ground truth shape: (842, 640)\n",
      "indices = 0 shape: (521713, 2)\n",
      "indices = 1 shape: (17167, 2)\n",
      "(2000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 32/32 [00:25<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1004/2000\n",
      "tes: 12\n",
      "img shape: (836, 572, 224)\n",
      "img shape after padding (844, 580, 224)\n",
      "number of pixel 478192\n",
      "ground truth shape: (836, 572)\n",
      "indices = 0 shape: (439255, 2)\n",
      "indices = 1 shape: (38937, 2)\n",
      "(2000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 32/32 [00:25<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1000/2000\n",
      "tes: 13\n",
      "img shape: (1342, 527, 224)\n",
      "img shape after padding (1350, 535, 224)\n",
      "number of pixel 707234\n",
      "ground truth shape: (1342, 527)\n",
      "indices = 0 shape: (660450, 2)\n",
      "indices = 1 shape: (46784, 2)\n",
      "(2000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 32/32 [00:23<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1000/2000\n",
      "tes: 14\n",
      "img shape: (1260, 523, 224)\n",
      "img shape after padding (1268, 531, 224)\n",
      "number of pixel 658980\n",
      "ground truth shape: (1260, 523)\n",
      "indices = 0 shape: (633355, 2)\n",
      "indices = 1 shape: (25625, 2)\n",
      "(2000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 32/32 [00:23<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1000/2000\n",
      "tes: 15\n",
      "img shape: (1033, 437, 224)\n",
      "img shape after padding (1041, 445, 224)\n",
      "number of pixel 451421\n",
      "ground truth shape: (1033, 437)\n",
      "indices = 0 shape: (429484, 2)\n",
      "indices = 1 shape: (21937, 2)\n",
      "(2000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 32/32 [00:24<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1000/2000\n",
      "tes: 16\n",
      "img shape: (600, 400, 224)\n",
      "img shape after padding (608, 408, 224)\n",
      "number of pixel 240000\n",
      "ground truth shape: (600, 400)\n",
      "indices = 0 shape: (185193, 2)\n",
      "indices = 1 shape: (54807, 2)\n",
      "(2000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 32/32 [00:22<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1000/2000\n",
      "tes: 17\n",
      "img shape: (1175, 563, 224)\n",
      "img shape after padding (1183, 571, 224)\n",
      "number of pixel 661525\n",
      "ground truth shape: (1175, 563)\n",
      "indices = 0 shape: (587602, 2)\n",
      "indices = 1 shape: (73923, 2)\n",
      "(2000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 32/32 [00:24<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1000/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64  # You can change this depending on your GPU capacity\n",
    "\n",
    "model_name = model_path.split('\\\\')[-1]\n",
    "\n",
    "print(f\"Creating model {model_name}...\")\n",
    "saved_model = VGG16_HSI().to(device)\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "saved_model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"Model loaded and moved to device\")\n",
    "\n",
    "patch_size = 9\n",
    "half_patch = patch_size // 2\n",
    "\n",
    "scores = []\n",
    "\n",
    "for dataset in range(len(datasets)):\n",
    "    print(f\"tes: {dataset}\")\n",
    "    test_indices, test_gt, matrix = testWithDataset(dataset)\n",
    "\n",
    "    total = len(test_indices)\n",
    "    correct0 = 0\n",
    "    correct1 = 0\n",
    "\n",
    "    input_patches = []\n",
    "    true_labels = []\n",
    "\n",
    "    # Prepare all patches\n",
    "    for x_pos, y_pos in test_indices:\n",
    "        true_label = test_gt[x_pos][y_pos]\n",
    "\n",
    "        selected_rows = matrix[x_pos:x_pos + 2*half_patch + 1, :]\n",
    "        testing_patch = selected_rows[:, y_pos:y_pos + 2*half_patch + 1]\n",
    "\n",
    "        patch_tensor = torch.tensor(testing_patch, dtype=torch.float32)\n",
    "        patch_tensor = patch_tensor.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "\n",
    "        input_patches.append(patch_tensor)\n",
    "        true_labels.append(true_label)\n",
    "\n",
    "    input_patches = torch.cat(input_patches, dim=0)  # Shape: (N, C, H, W)\n",
    "    true_labels = torch.tensor(true_labels)\n",
    "\n",
    "    # Process in batches\n",
    "    for i in tqdm(range(0, total, batch_size), desc=\"Predicting\"):\n",
    "        batch = input_patches[i:i+batch_size]\n",
    "        labels = true_labels[i:i+batch_size]\n",
    "\n",
    "        preds, confs = predict_batch(saved_model, batch, device)\n",
    "\n",
    "        for j in range(len(preds)):\n",
    "            index = i + j\n",
    "            # print(f\"{index+1}: prediction = {preds[j]}, confidence: {confs[j]:.4f}, expected: {labels[j].item()}\")\n",
    "            if preds[j] == labels[j].item():\n",
    "                if labels[j].item() == 0:\n",
    "                    correct0 += 1\n",
    "                elif labels[j] == 1:\n",
    "                    correct1 += 1\n",
    "\n",
    "    correct = correct0 + correct1\n",
    "    print(f\"Score: {correct}/{total}\")\n",
    "    \n",
    "    scores.append((f\"dataset{dataset}\", f'{correct0}/{total/2}', f'{correct1}/{total/2}', f'{correct}/{total}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f93559e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dataset0', '9/1000.0', '988/1000.0', '997/2000')\n",
      "('dataset1', '248/1000.0', '769/1000.0', '1017/2000')\n",
      "('dataset2', '654/1000.0', '594/1000.0', '1248/2000')\n",
      "('dataset3', '218/1000.0', '798/1000.0', '1016/2000')\n",
      "('dataset4', '941/1000.0', '473/1000.0', '1414/2000')\n",
      "('dataset5', '884/1000.0', '144/1000.0', '1028/2000')\n",
      "('dataset6', '0/1000.0', '1000/1000.0', '1000/2000')\n",
      "('dataset7', '0/1000.0', '1000/1000.0', '1000/2000')\n",
      "('dataset8', '0/1000.0', '1000/1000.0', '1000/2000')\n",
      "('dataset9', '0/1000.0', '1000/1000.0', '1000/2000')\n",
      "('dataset10', '0/1000.0', '1000/1000.0', '1000/2000')\n",
      "('dataset11', '4/1000.0', '1000/1000.0', '1004/2000')\n",
      "('dataset12', '0/1000.0', '1000/1000.0', '1000/2000')\n",
      "('dataset13', '0/1000.0', '1000/1000.0', '1000/2000')\n",
      "('dataset14', '0/1000.0', '1000/1000.0', '1000/2000')\n",
      "('dataset15', '0/1000.0', '1000/1000.0', '1000/2000')\n",
      "('dataset16', '0/1000.0', '1000/1000.0', '1000/2000')\n",
      "('dataset17', '0/1000.0', '1000/1000.0', '1000/2000')\n"
     ]
    }
   ],
   "source": [
    "for score in scores:\n",
    "    print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
