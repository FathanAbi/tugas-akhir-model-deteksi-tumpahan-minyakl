{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\Asus TUF\\\\Documents\\\\code\\\\TA\\\\models\\\\model_1000_noaugment\\\\model_20250302_134234_0', 'C:\\\\Users\\\\Asus TUF\\\\Documents\\\\code\\\\TA\\\\models\\\\model_1000_noaugment\\\\model_20250302_134234_2', 'C:\\\\Users\\\\Asus TUF\\\\Documents\\\\code\\\\TA\\\\models\\\\model_1000_noaugment\\\\model_20250302_134234_3', 'C:\\\\Users\\\\Asus TUF\\\\Documents\\\\code\\\\TA\\\\models\\\\model_1000_noaugment\\\\model_20250302_134234_5']\n"
     ]
    }
   ],
   "source": [
    "import VGG as vgg\n",
    "import torch\n",
    "from HSI_class import HSI\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "PATH = r\"C:\\Users\\Asus TUF\\Documents\\code\\TA\\models\\model_800train\\model_20250228_175649_1\"\n",
    "\n",
    "\n",
    "print(\"creating model...\")\n",
    "saved_model = vgg.VGG16_HSI()\n",
    "saved_model.load_state_dict(torch.load(PATH))\n",
    "print(\"model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"Hyperspectral oil spill detection datasets\"\n",
    "\n",
    "dataset = []\n",
    "\n",
    "i = 0\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if i > 3:\n",
    "        break\n",
    "    file_path = os.path.join(dataset_path, filename)\n",
    "    if os.path.isfile(file_path):  # Check if it's a file\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        hsi = HSI(file_path)\n",
    "        dataset.append(hsi)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zeroPadding\n",
    "hsi_test = dataset[2]\n",
    "\n",
    "test_img = hsi_test.img\n",
    "test_gt = hsi_test.gt\n",
    "\n",
    "patch_size = 9\n",
    "half_patch = patch_size // 2\n",
    "\n",
    "height = test_img.shape[0]\n",
    "width = test_img.shape[1]\n",
    "\n",
    "matrix=zeroPadding.zeroPadding_3D(test_img,half_patch) #add 0 in every side of the data\n",
    "print(f\"img shape: {test_img.shape}\")\n",
    "print(f\"img shape after padding {matrix.shape}\")\n",
    "print(f\"number of pixel {width * height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input):\n",
    "\n",
    "    with torch.no_grad():  # Disable gradients for inference\n",
    "        output = saved_model(input)\n",
    "\n",
    "    # Convert logits to class label\n",
    "    predicted_class = torch.argmax(output, dim=1).item()\n",
    "    confidence = torch.nn.functional.softmax(output, dim=1)[0, predicted_class].item()\n",
    "\n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_gt.shape)\n",
    "\n",
    "indices0 = np.argwhere(test_gt == 0)\n",
    "indices1 = np.argwhere(test_gt == 1)\n",
    "\n",
    "print(indices0.shape)\n",
    "print(indices1.shape)\n",
    "\n",
    "num_samples = 100\n",
    "\n",
    "random_indices0 = indices0[np.random.choice(len(indices0), num_samples, replace=False)]\n",
    "random_indices1 = indices1[np.random.choice(len(indices1), num_samples, replace=False)]\n",
    "\n",
    "test_indices = np.vstack((random_indices0, random_indices1))\n",
    "\n",
    "print(test_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "i = 0\n",
    "for indice in test_indices:\n",
    "    x_pos = indice[0]\n",
    "    y_pos = indice[1]\n",
    "\n",
    "    true_label = test_gt[x_pos][y_pos]\n",
    "\n",
    "    selected_rows = matrix[range(x_pos,x_pos+2*half_patch+1), :]\n",
    "    testing_patch = selected_rows[:, range(y_pos, y_pos+2*half_patch+1)]\n",
    "    \n",
    "    # print(i)\n",
    "    # print(testing_patch[half_patch][half_patch])\n",
    "    # print(test_img[x_pos][y_pos])\n",
    "\n",
    "    testing_patch = torch.tensor(testing_patch)\n",
    "    testing_patch = testing_patch.to(torch.float32)\n",
    "    testing_patch = testing_patch.unsqueeze(0)\n",
    "    testing_patch = testing_patch.permute(0, 3, 1, 2)\n",
    "\n",
    "    prediction, confidence = predict(testing_patch)\n",
    "\n",
    "    print(f\"{i+1}: prediction = {prediction}, confidence: {confidence}, expected: {true_label}\")\n",
    "    \n",
    "    if(prediction == true_label):\n",
    "        correct += 1\n",
    "\n",
    "    total += 1\n",
    "    i += 1\n",
    "\n",
    "print(f\"skor: {correct}/{total}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
