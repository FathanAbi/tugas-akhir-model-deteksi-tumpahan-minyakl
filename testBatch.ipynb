{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus TUF\\Documents\\code\\TA\\simsiam\\simsiam\\models\\best_model\\20250420_153751_checkpoint_0010.pth.tar\n",
      "C:\\Users\\Asus TUF\\Documents\\code\\TA\\simsiam\\simsiam\\models\\best_model\\checkpoint_0009.pth.tar\n",
      "C:\\Users\\Asus TUF\\Documents\\code\\TA\\simsiam\\simsiam\\models\\best_model\\checkpoint_0010.pth.tar\n"
     ]
    }
   ],
   "source": [
    "import VGG as vgg\n",
    "import torch\n",
    "from HSI_class import HSI\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "directory = r\"C:\\Users\\Asus TUF\\Documents\\code\\TA\\simsiam\\simsiam\\models\\best_model\"\n",
    "files = [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "# directory2 = r\"C:\\Users\\Asus TUF\\Documents\\code\\TA\\models\\model_800train\"\n",
    "# files2 = [os.path.join(directory2, f) for f in os.listdir(directory2) if os.path.isfile(os.path.join(directory2, f))]\n",
    "\n",
    "\n",
    "models = []\n",
    "\n",
    "for file in files:\n",
    "    models.append(file)\n",
    "\n",
    "# for file in files2:\n",
    "#     models.append(file)\n",
    "\n",
    "for model in models:\n",
    "    print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Hyperspectral oil spill detection datasets\\GM01.mat\n",
      "Processing file: Hyperspectral oil spill detection datasets\\GM02.mat\n",
      "Processing file: Hyperspectral oil spill detection datasets\\GM03.mat\n",
      "Processing file: Hyperspectral oil spill detection datasets\\GM04.mat\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"Hyperspectral oil spill detection datasets\"\n",
    "\n",
    "dataset = []\n",
    "\n",
    "i = 0\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if i > 3:\n",
    "        break\n",
    "    file_path = os.path.join(dataset_path, filename)\n",
    "    if os.path.isfile(file_path):  # Check if it's a file\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        hsi = HSI(file_path)\n",
    "        dataset.append(hsi)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape: (1386, 690, 224)\n",
      "img shape after padding (1394, 698, 224)\n",
      "number of pixel 956340\n"
     ]
    }
   ],
   "source": [
    "import zeroPadding\n",
    "hsi_test = dataset[2]\n",
    "\n",
    "test_img = hsi_test.img\n",
    "test_gt = hsi_test.gt\n",
    "\n",
    "patch_size = 9\n",
    "half_patch = patch_size // 2\n",
    "\n",
    "height = test_img.shape[0]\n",
    "width = test_img.shape[1]\n",
    "\n",
    "matrix=zeroPadding.zeroPadding_3D(test_img,half_patch) #add 0 in every side of the data\n",
    "print(f\"img shape: {test_img.shape}\")\n",
    "print(f\"img shape after padding {matrix.shape}\")\n",
    "print(f\"number of pixel {width * height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1386, 690)\n",
      "(916980, 2)\n",
      "(39360, 2)\n",
      "(2000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(test_gt.shape)\n",
    "\n",
    "indices0 = np.argwhere(test_gt == 0)\n",
    "indices1 = np.argwhere(test_gt == 1)\n",
    "\n",
    "print(indices0.shape)\n",
    "print(indices1.shape)\n",
    "\n",
    "num_samples = 1000\n",
    "\n",
    "random_indices0 = indices0[np.random.choice(len(indices0), num_samples, replace=False)]\n",
    "random_indices1 = indices1[np.random.choice(len(indices1), num_samples, replace=False)]\n",
    "\n",
    "test_indices = np.vstack((random_indices0, random_indices1))\n",
    "\n",
    "print(test_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_batch(model, batch_input, device):\n",
    "    model.eval()\n",
    "    batch_input = batch_input.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_input)\n",
    "\n",
    "    predicted_classes = torch.argmax(output, dim=1).cpu().numpy()\n",
    "    confidences = torch.nn.functional.softmax(output, dim=1)\n",
    "    confidences = confidences[range(len(predicted_classes)), predicted_classes].cpu().numpy()\n",
    "\n",
    "    return predicted_classes, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg16\n",
    "import torch.nn as nn\n",
    "\n",
    "class VGG16_HSI(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(VGG16_HSI, self).__init__()\n",
    "\n",
    "         # Custom Convolutional Layer: Process 9x9x224 input\n",
    "        self.pre_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=224, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))  # Reduce to (256, 1, 1)\n",
    "        )\n",
    "\n",
    "        # Fully Connected Layer to reshape to (64, 56, 56)\n",
    "        self.fc = nn.Linear(256 * 1 * 1, 64 * 56 * 56)\n",
    "\n",
    "        # Load VGG-16 Model\n",
    "        self.encoder = vgg16(pretrained=False)\n",
    "\n",
    "        # Remove first VGG-16 conv layer\n",
    "        self.encoder.features = nn.Sequential(*list(self.encoder.features.children())[1:])\n",
    "\n",
    "        # Modify classifier to output 2 classes\n",
    "        self.encoder.classifier[6] = nn.Linear(4096, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(f'before {x.shape}')\n",
    "        x = self.pre_conv(x)  # Process hyperspectral input\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "\n",
    "        # print(f'after preconv {x.shape}')\n",
    "        x = self.fc(x)  # Fully connected layer\n",
    "        # print(f'after fc {x.shape}')\n",
    "        # Reshape to (batch_size, 64, 56, 56) before passing to VGG\n",
    "        x = x.view(x.size(0), 64, 56, 56)\n",
    "        # print(f'after reshape, before vgg second layer {x.shape}')\n",
    "\n",
    "        x = self.encoder.features(x)  # Pass to VGG-16\n",
    "        x = self.encoder.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.encoder.classifier(x)  # Final classification layer\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model 20250420_153751_checkpoint_0010.pth.tar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus TUF\\Documents\\code\\TA\\myenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Asus TUF\\Documents\\code\\TA\\myenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Asus TUF\\AppData\\Local\\Temp\\ipykernel_3864\\2945208158.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and moved to device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 32/32 [00:02<00:00, 13.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1552/2000\n",
      "Creating model checkpoint_0009.pth.tar...\n",
      "Model loaded and moved to device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 32/32 [00:02<00:00, 15.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1364/2000\n",
      "Creating model checkpoint_0010.pth.tar...\n",
      "Model loaded and moved to device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 32/32 [00:02<00:00, 15.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1365/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64  # You can change this depending on your GPU capacity\n",
    "scores = []\n",
    "\n",
    "for model_path in models:\n",
    "    model_name = model_path.split('\\\\')[-1]\n",
    "    print(f\"Creating model {model_name}...\")\n",
    "    saved_model = VGG16_HSI().to(device)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    saved_model.load_state_dict(checkpoint['state_dict'])\n",
    "    print(\"Model loaded and moved to device\")\n",
    "\n",
    "    total = len(test_indices)\n",
    "    correct0 = 0\n",
    "    correct1 = 0\n",
    "\n",
    "    input_patches = []\n",
    "    true_labels = []\n",
    "\n",
    "    # Prepare all patches\n",
    "    for x_pos, y_pos in test_indices:\n",
    "        true_label = test_gt[x_pos][y_pos]\n",
    "\n",
    "        selected_rows = matrix[x_pos:x_pos + 2*half_patch + 1, :]\n",
    "        testing_patch = selected_rows[:, y_pos:y_pos + 2*half_patch + 1]\n",
    "\n",
    "        patch_tensor = torch.tensor(testing_patch, dtype=torch.float32)\n",
    "        patch_tensor = patch_tensor.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "\n",
    "        input_patches.append(patch_tensor)\n",
    "        true_labels.append(true_label)\n",
    "\n",
    "    input_patches = torch.cat(input_patches, dim=0)  # Shape: (N, C, H, W)\n",
    "    true_labels = torch.tensor(true_labels)\n",
    "\n",
    "    # Process in batches\n",
    "    for i in tqdm(range(0, total, batch_size), desc=\"Predicting\"):\n",
    "        batch = input_patches[i:i+batch_size]\n",
    "        labels = true_labels[i:i+batch_size]\n",
    "\n",
    "        preds, confs = predict_batch(saved_model, batch, device)\n",
    "\n",
    "        for j in range(len(preds)):\n",
    "            index = i + j\n",
    "            # print(f\"{index+1}: prediction = {preds[j]}, confidence: {confs[j]:.4f}, expected: {labels[j].item()}\")\n",
    "            if preds[j] == labels[j].item():\n",
    "                if labels[j].item() == 0:\n",
    "                    correct0 += 1\n",
    "                elif labels[j] == 1:\n",
    "                    correct1 += 1\n",
    "\n",
    "    correct = correct0 + correct1\n",
    "    print(f\"Score: {correct}/{total}\")\n",
    "    \n",
    "    scores.append((model_name, f'{correct0}/{total/2}', f'{correct1}/{total/2}', f'{correct}/{total}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "('20250420_153751_checkpoint_0010.pth.tar', '900/1000.0', '652/1000.0', '1552/2000')\n",
      "('checkpoint_0009.pth.tar', '989/1000.0', '375/1000.0', '1364/2000')\n",
      "('checkpoint_0010.pth.tar', '989/1000.0', '376/1000.0', '1365/2000')\n"
     ]
    }
   ],
   "source": [
    "print(total)\n",
    "for score in scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
